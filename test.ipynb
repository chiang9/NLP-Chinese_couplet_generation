{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3661af25",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "boolean-diving",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install pypinyin\n",
    "!pip install jieba\n",
    "!pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e97bf95",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "metropolitan-times",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AnchiBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re,time,json\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import (BertTokenizer,BertConfig,BertModel)\n",
    "\n",
    "from model.fusionDataset import FusionDataset\n",
    "\n",
    "config = BertConfig.from_pretrained('AnchiBERT')\n",
    "tokenizer = BertTokenizer.from_pretrained('AnchiBERT')\n",
    "Anchibert = BertModel.from_pretrained('AnchiBERT',config=config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b2460",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "stable-checkout",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "source": [
    "### Load Necessary preproceeded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc18ba9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "funky-measurement",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/char_map.json','r') as f:\n",
    "    ix2glyph = defaultdict(lambda : '_')\n",
    "    ix2glyph[0] = '[PAD]'\n",
    "    glyph2ix = defaultdict(lambda : 1)\n",
    "    glyph2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    for i, k in enumerate(json.load(f).keys(),2):\n",
    "        glyph2ix[k] = i\n",
    "        ix2glyph[i] = k\n",
    "with open('data/pinyin_map.json','r') as f:\n",
    "    pinyin2ix = defaultdict(lambda : 1)\n",
    "    pinyin2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    for i,k in enumerate(json.load(f).keys(),2):\n",
    "        pinyin2ix[k] = i\n",
    "with open('data/pos_tags.json','r') as f:\n",
    "    pos2ix = defaultdict(lambda : 0)\n",
    "    pos2ix.update(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cbe1c",
   "metadata": {},
   "source": [
    "# Decoder Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3828f3ae",
   "metadata": {
    "gradient": {
     "execution_count": 14,
     "id": "protective-sixth",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "from model.fusion_transformer import Fusion_Anchi_Trans_Decoder, Fusion_Anchi_Transformer, Anchi_Decoder,Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91c36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"couplet/test/in.txt\",encoding='utf8') as f:\n",
    "    te_in =  [row.strip().split() for row in f.readlines()]\n",
    "# train 下联  \n",
    "with open(\"couplet/test/out.txt\",encoding='utf8') as f:\n",
    "    te_out = [row.strip().split() for row in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c285d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { # for Fusion_Anchi_Trans_Decoder\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30, # trainable\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10, # trainable\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_layers':6 , #6, trainable\n",
    "    'output_dim':9110,# fixed\n",
    "    'device':device,\n",
    "}\n",
    "model = Fusion_Anchi_Trans_Decoder(config)\n",
    "model.load_state_dict(torch.load('result/fu_anchi_de_Adam_128_0001_60_6_30_10_110k.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5112591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_couplet import greedy_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79271210",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = greedy_decode(model=model,\n",
    "                      bert=Anchibert,\n",
    "                      tokenizer=tokenizer,\n",
    "                      sent=te_in[0],\n",
    "                      glyph2ix=glyph2ix,\n",
    "                      pinyin2ix=pinyin2ix,\n",
    "                      pos2ix=pos2ix,\n",
    "                      ix2glyph=ix2glyph,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e66c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('腾 飞 上 铁 ， 锐 意 改 革 谋 发 展 ， 勇 当 千 里 马', '是 是 是 是 ， 是 是 是 是 是 是 是 ， 是 是 是 是 是')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(te_in[0]),' '.join(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
