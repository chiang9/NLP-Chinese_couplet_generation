{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817dcb9-150c-4739-8906-c4ea6a7c0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130ff9c-052e-46c6-8ea2-a4778a3a0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用的paddlenlp的word embeddings，具体看 https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/embeddings.md\n",
    "# data封装类型还没弄懂 把batch封装好了就能train了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a579f1e-6eb3-403d-a3d6-a47803294e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import timeit\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18458aa6-5e29-461a-bcaa-00e8611bb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_in = open(\"couplet/train/in.txt\",encoding='utf8').read()\n",
    "tr_out = open(\"couplet/train/out.txt\",encoding='utf8').read()\n",
    "te_in = open(\"couplet/test/in.txt\",encoding='utf8').read()\n",
    "te_out = open(\"couplet/test/out.txt\",encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356c600-cbaa-4db9-8810-28ece4d4643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(zip(te_in.split('\\n')[:-1], te_out.split('\\n')[:-1]))\n",
    "dev =  list(zip(tr_in.split('\\n')[-3000:], tr_out.split('\\n')[-3000:]))\n",
    "train = list(zip(tr_in.split('\\n')[:-3000], tr_out.split('\\n')[:-3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c1d3d-0a72-4fef-bccd-33713c9379dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tr_in.split('\\n')),len(train),len(dev),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e28bf-1853-4009-b542-0da7fd89a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "\n",
    "token_embedding = TokenEmbedding(embedding_name=\"w2v.baidu_encyclopedia.target.word-word.dim300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b63c9-b912-4075-93ba-7948fc49c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(tr_in + tr_out + te_in + te_out))\n",
    "\n",
    "embeddings = dict()\n",
    "for w in vocab:\n",
    "    embeddings[w] = token_embedding.search(w).reshape(300,)\n",
    "\n",
    "embeddings['<s>'] = np.random.rand(300,).astype('float32') *2 - 1 # range(-1:1)\n",
    "embeddings['<e>'] = np.random.rand(300,).astype('float32') *2 - 1 # range(-1:1)\n",
    "embeddings['<pad>'] = np.zeros(300,)\n",
    "vocab.insert(0,'<e>')\n",
    "vocab.insert(0,'<s>')\n",
    "vocab.insert(0,'<pad>')\n",
    "# creating word2id lookup dictionary\n",
    "word2id = {w:i for i,w in enumerate(embeddings,start=3)}\n",
    "word2id['<pad>'] = 0\n",
    "word2id['<s>'] = 1\n",
    "word2id['<e>'] = 2 \n",
    "id2word = {i:w for w,i in word2id.items()}\n",
    "\n",
    "max_sts_len = 20\n",
    "\n",
    "len(vocab),len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae7a95-7367-4010-9f19-d2ebf17b93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[0],id2word[1],id2word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3ea12-3d16-4d33-b9cf-d442e683ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = train[0][0]\n",
    "['<s>'] + sent.split() + ['<e>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f714f1-2e11-447d-ba2a-456b522c91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(sent,embeddings,max_sts_len=20): ##upper为输入的上联\n",
    "\n",
    "    word_list = []\n",
    "    #review = upper.strip().split(' ')\n",
    "    review = ['<s>'] + sent.split() + ['<e>'] ##开头加符号1，结束加符号2\n",
    "    \n",
    "    if len(review) >= max_sts_len:\n",
    "        review = review[:max_sts_len]\n",
    "        origanal_len = max_sts_len\n",
    "    else:\n",
    "        origanal_len = len(review)\n",
    "        for i in range(len(review), max_sts_len):\n",
    "            review.append('<pad>') ## 词向量维度为200\n",
    "            \n",
    "    for word in review:                        \n",
    "        embedding_vector = embeddings[word]\n",
    "        word_list.append(embedding_vector)   \n",
    "\n",
    "    #word_list.append([origanal_len for j in range(300)]) ## 最后一行元素为句子实际长度\n",
    "    word_list = np.stack(word_list) \n",
    "    \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a1761-fc97-479b-8b5a-f9feb7e03d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_y(sent,word2ix,max_sts_len=20):\n",
    "\n",
    "    word_list = [1] ##开头加起始符号1\n",
    "    for word in sent.split():\n",
    "        word_idx = word2ix[word]\n",
    "        word_list.append(word_idx)\n",
    "    word_list.append(2) ##结束加终止符号2\n",
    "    \n",
    "    if len(word_list) >= max_sts_len:\n",
    "        origanal_len = max_sts_len\n",
    "        word_list = word_list[:max_sts_len]\n",
    "    else:\n",
    "        origanal_len = len(word_list)\n",
    "        for i in range(len(word_list), max_sts_len):\n",
    "            word_list.append(0) ## 不够长度则补0  \n",
    "    #word_list.append(origanal_len) ##最后一个元素为句子长度\n",
    "    \n",
    "    return np.array(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7d026-6845-4e7b-9b9b-dd9f7b6f22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(i,len(k[0].split())) for i,k in enumerate(train) if len(k[0].split()) >= 20]\n",
    "sent_x,sent_y = train[0][0],train[0][1]#,train[12864][0]\n",
    "prepare_x(sent_x,embeddings).shape,sent_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e56148-eccc-4e1f-8c0d-b4b606976889",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_y(sent_y,word2id),sent_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0556a1-723e-4b70-a2e8-a5ec63894d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    " \n",
    "        self.embedding_dim = embedding_dim #词向量维度，本项目中是200维\n",
    "        self.hidden_dim = hidden_dim #RNN隐层维度\n",
    "        self.num_layers = num_layers #RNN层数\n",
    "        self.dropout = dropout  #dropout\n",
    " \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    " \n",
    "        self.dropout = nn.Dropout(dropout) #dropout层\n",
    " \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # src = [sent len, batch size]\n",
    "        embedded = self.dropout(input_seqs)\n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        #packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths) #将输入转换成torch中的pack格式，使得RNN输入的是真实长度的句子而非padding后的\n",
    "        #outputs, hidden = self.rnn(packed, hidden)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        #outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # outputs, hidden = self.rnn(embedded, hidden)\n",
    "        # outputs = [sent len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # outputs are always from the last layer\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f6684-02c3-42a0-922f-3e4ba87372af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attn = nn.Linear(self.hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "        self.v.data.normal_(mean=0, std=1. / np.sqrt(self.v.size(0)))\n",
    " \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        #  encoder_outputs:(seq_len, batch_size, hidden_size)\n",
    "        #  hidden:(num_layers * num_directions, batch_size, hidden_size)\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        h = hidden[-1].repeat(max_len, 1, 1)\n",
    "        # (seq_len, batch_size, hidden_size)\n",
    "        attn_energies = self.score(h, encoder_outputs)  # compute attention score\n",
    "        return F.softmax(attn_energies, dim=1)  # normalize with softmax\n",
    " \n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # (seq_len, batch_size, 2*hidden_size)-> (seq_len, batch_size, hidden_size)\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.permute(1, 2, 0)  # (batch_size, hidden_size, seq_len)\n",
    "        v = self.v.repeat(encoder_outputs.size(1), 1).unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "        energy = torch.bmm(v, energy)  # (batch_size, 1, seq_len)\n",
    "        return energy.squeeze(1)  # (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c02c73-0247-4605-b2cf-9db82418ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    " \n",
    "        self.embedding_dim = embedding_dim ##编码维度\n",
    "        self.hid_dim = hidden_dim ##RNN隐层单元数\n",
    "        self.output_dim = output_dim ##词袋大小\n",
    "        self.num_layers = num_layers ##RNN层数\n",
    "        self.dropout = dropout\n",
    " \n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim + hidden_dim, hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(embedding_dim + hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    " \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input = [bsz]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # encoder_outputs = [sent len, batch size, hid dim * n directions]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, bsz]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, bsz, emb dim]\n",
    "        attn_weight = self.attention(hidden, encoder_outputs)\n",
    "        # (batch_size, seq_len)\n",
    "        context = attn_weight.unsqueeze(1).bmm(encoder_outputs.transpose(0, 1)).transpose(0, 1)\n",
    "        # (batch_size, 1, hidden_dim * n_directions)\n",
    "        # (1, batch_size, hidden_dim * n_directions)\n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        # emb_con = [1, bsz, emb dim + hid dim]\n",
    "        _, hidden = self.rnn(emb_con, hidden)\n",
    "        # outputs = [sent len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        output = torch.cat((embedded.squeeze(0), hidden[-1], context.squeeze(0)), dim=1)\n",
    "        output = F.log_softmax(self.out(output), 1)\n",
    "        # outputs = [sent len, batch size, vocab_size]\n",
    "        return output, hidden, attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b50c53-cbdf-4b14-8d1d-72508a063c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    " \n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    " \n",
    "    def forward(self, src_seqs, src_lengths, trg_seqs):\n",
    "        # src_seqs = [sent len, batch size]\n",
    "        # trg_seqs = [sent len, batch size]\n",
    "        batch_size = src_seqs.shape[1]\n",
    "        max_len = trg_seqs.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        # hidden used as the initial hidden state of the decoder\n",
    "        # encoder_outputs used to compute context\n",
    "        encoder_outputs, hidden = self.encoder(src_seqs, src_lengths)\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        output = trg_seqs[0, :]\n",
    " \n",
    "        for t in range(1, max_len): # skip sos\n",
    "            output, hidden, _ = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            output = (trg_seqs[t] if teacher_force else output.max(1)[1])\n",
    "        return outputs\n",
    " \n",
    "    def predict(self, src_seqs, src_lengths, max_trg_len=30, start_ix=1):\n",
    "        max_src_len = src_seqs.shape[0]\n",
    "        batch_size = src_seqs.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(max_trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src_seqs, src_lengths)\n",
    "        output = torch.LongTensor([start_ix] * batch_size).to(self.device)\n",
    "        attn_weights = torch.zeros((max_trg_len, batch_size, max_src_len))\n",
    "        for t in range(1, max_trg_len):\n",
    "            output, hidden, attn_weight = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            output = output.max(1)[1]\n",
    "            #attn_weights[t] = attn_weight\n",
    "        return outputs, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41998b5-ee75-4be1-9a9f-4007a9fd22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "en=Encoder(300,256) ##词向量维度300，rnn隐单元256\n",
    "de=Decoder(len(word2id),300,256) ##词袋大小9132，词向量维度300，rnn隐单元256\n",
    "network = Net(en,de,device) ##定义Seq2Seq实例\n",
    "loss_fn = nn.CrossEntropyLoss() ##使用交叉熵损失函数\n",
    "optimizer = optim.Adam(network.parameters(),lr=0.01) ##使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8671616-3956-460f-8256-c992ae8f77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loader, (batch data)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d939b2-358e-4cb7-8879-fd2284754791",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_loss = 10\n",
    "EPOCHS = 5\n",
    "# 得到训练和测试的数据\n",
    "for epoch in range(EPOCHS):\n",
    "    network.train()\n",
    "    \n",
    "    # 得到训练和测试的数据\n",
    "    x_train, y_train, x_test, y_test = data.next_batch(BATCH)  # 读取数据; shape:(sen_len,batch,embedding)\n",
    "    #x_train shape: (batch,sen_len,embed_dim)\n",
    "    #y_train shape: (batch,sen_len)\n",
    "    batch_len = y_train.shape[0]\n",
    "    #input_lengths = [30 for i in range(batch_len)] ## batch内每个句子的长度\n",
    "    input_lengths = x_train[:,-1,0]\n",
    "    input_lengths = input_lengths.tolist()\n",
    "    #input_lengths = list(map(lambda x: int(x),input_lengths))\n",
    "    input_lengths = [int(x) for x in input_lengths]\n",
    "    y_lengths = y_train[:,-1]\n",
    "    y_lengths = y_lengths.tolist()\n",
    "    \n",
    "    x_train = x_train[:,:-1,:] ## 除去长度信息\n",
    "    x_train = torch.from_numpy(x_train) #shape:(batch,sen_len,embedding)\n",
    "    x_train = x_train.float().to(device) \n",
    "    y_train = y_train[:,:-1] ## 除去长度信息\n",
    "    y_train = torch.from_numpy(y_train) #shape:(batch,sen_len)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_train = y_train.to(device) \n",
    " \n",
    "    seq_pairs = sorted(zip(x_train.contiguous(), y_train.contiguous(),input_lengths), key=lambda x: x[2], reverse=True)\n",
    "    #input_lengths = sorted(input_lengths, key=lambda x: input_lengths, reverse=True)\n",
    "    x_train, y_train,input_lengths = zip(*seq_pairs)\n",
    "    x_train = torch.stack(x_train,dim=0).permute(1,0,2).contiguous()\n",
    "    y_train = torch.stack(y_train,dim=0).permute(1,0).contiguous()\n",
    " \n",
    "    outputs = network(x_train,input_lengths,y_train)\n",
    "    \n",
    "    #_, prediction = torch.max(outputs.data, 2)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    outputs = outputs.float()\n",
    "    # calculate the loss according to labels\n",
    "    loss = loss_fn(outputs.view(-1, outputs.shape[2]), y_train.view(-1))\n",
    " \n",
    "    # backward transmit loss\n",
    "    loss.backward()\n",
    "    # adjust parameters using Adam\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    " \n",
    "    # 若测试准确率高于当前最高准确率，则保存模型\n",
    " \n",
    "    if loss < lowest_loss:\n",
    "        lowest_loss = loss\n",
    "        model.save_model(network, MODEL_PATH, overwrite=True)\n",
    "        print(\"step %d, best lowest_loss %g\" % (epoch, lowest_loss))\n",
    "    print(str(epoch) + \"/\" + str(args.EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5c48d-46eb-45b4-bed8-a318d127b4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
