{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "aging-optimum",
=======
   "execution_count": null,
   "id": "express-invite",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "boolean-diving",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install pypinyin\n",
    "!pip install jieba\n",
    "!pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agreed-screening",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "metropolitan-times",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Some weights of the model checkpoint at AnchiBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
=======
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Some weights of the model checkpoint at AnchiBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re,time,json\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from pypinyin import pinyin, Style\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import (BertTokenizer,BertConfig,BertModel)\n",
    "\n",
    "from model.Embedding import *\n",
    "from model.fusionDataset import FusionDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import paddle\n",
    "\n",
    "config = BertConfig.from_pretrained('AnchiBERT')\n",
    "tokenizer = BertTokenizer.from_pretrained('AnchiBERT')\n",
    "Anchibert = BertModel.from_pretrained('AnchiBERT',config=config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-samoa",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "asian-sustainability",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "source": [
    "### Example for glyph + pinyin embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
   "id": "revised-williams",
=======
   "id": "appointed-homeless",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "sporting-netscape",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0720, -0.0596,  0.0230,  ...,  0.0150, -0.0975, -0.0763],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2629,  0.0584, -0.0224, -0.1282,  0.2653,  0.2522,  0.0376,  0.0921,\n",
       "          0.0478,  0.1703,  0.2385, -0.1221,  0.1052,  0.2103, -0.0876, -0.0335,\n",
       "         -0.2250,  0.2317, -0.2188,  0.2284, -0.0873, -0.0754, -0.0487, -0.1337,\n",
       "          0.0356,  0.0856, -0.1935,  0.0685,  0.2788,  0.2450]],\n",
=======
       "tensor([[ 0.2357, -0.2738, -0.2652,  0.1372, -0.0071, -0.3078,  0.0094,  0.0898,\n",
       "         -0.1926, -0.2237,  0.1600,  0.1161,  0.2236, -0.0088,  0.1961, -0.2132,\n",
       "          0.2560,  0.2003, -0.0597,  0.0148,  0.1607,  0.1465,  0.0915, -0.0037,\n",
       "         -0.2926,  0.2344,  0.2502,  0.0166, -0.0071,  0.0503],\n",
       "        [-0.1495, -0.2923, -0.2148, -0.2737, -0.1621,  0.2301,  0.2625,  0.1725,\n",
       "         -0.2636, -0.0225,  0.2649,  0.3154, -0.1482,  0.1330,  0.1423,  0.1166,\n",
       "          0.2852,  0.1410,  0.1775, -0.1640,  0.0467, -0.0750,  0.2550, -0.0938,\n",
       "          0.1038,  0.1584,  0.1917,  0.0675, -0.2958, -0.1075]],\n",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glyph = GlyphEmbedding('data/glyph_weight.npy')\n",
    "pinyinV = PinyinEmbedding(30,'data/pinyin_map.json')\n",
    "# Example\n",
    "display(glyph(torch.tensor([0,1,2])))\n",
    "display(pinyinV(torch.tensor([0,1])))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "closed-bolivia",
=======
   "execution_count": 3,
   "id": "pharmaceutical-usage",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "integrated-lodging",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  100, 6789,  689, 2591,  223,    0,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "_ = tokenizer('[UNK]辛业怠π[PAD]',return_tensors='pt')\n",
    "display(_)\n",
    "Anchibert(**_).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "thirty-cannon",
=======
   "execution_count": 4,
   "id": "solid-spelling",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "optimum-category",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '辛', '业', '怠', 'π', '[PAD]', '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(_['input_ids'][0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-parts",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "stable-checkout",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "source": [
    "### Load Necessary preproceeded Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "protected-vanilla",
=======
   "execution_count": 5,
   "id": "egyptian-residence",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "funky-measurement",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/char_map.json','r') as f:\n",
    "    glyph2ix = defaultdict(lambda : 1)\n",
    "    glyph2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    glyph2ix.update(json.load(f))\n",
    "\n",
    "with open('data/pinyin_map.json','r') as f:\n",
    "    pinyin2ix = defaultdict(lambda : 1)\n",
    "    pinyin2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    pinyin2ix.update(json.load(f))\n",
    "    \n",
    "with open('data/pos_tags.json','r') as f:\n",
    "    pos2ix = defaultdict(lambda : 0)\n",
    "    pos2ix.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "wrong-investigator",
=======
   "execution_count": 6,
   "id": "excellent-elite",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "whole-israeli",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "# train 上联\n",
    "with open(\"couplet/train/in.txt\",encoding='utf8') as f:\n",
    "    tr_in =  [row.strip().split() for row in f.readlines()]\n",
    "# train 下联  \n",
    "with open(\"couplet/train/out.txt\",encoding='utf8') as f:\n",
    "    tr_out = [row.strip().split() for row in f.readlines()]\n",
    "with open('data/train_in_pos.pt','rb') as f:\n",
    "    tr_pos_in = pickle.load(f)\n",
    "with open('data/train_out_pos.pt','rb') as f:\n",
    "    tr_pos_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "motivated-daisy",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "designing-stage",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(tr_in))\n",
    "total_len = len(tr_in)\n",
    "train_split = int(0.9 * total_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-numbers",
=======
   "execution_count": 31,
   "id": "improving-fundamental",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "played-lancaster",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "693441it [05:25, 2130.10it/s]\n",
      "693441it [05:15, 2199.27it/s]\n"
=======
      "693441it [04:58, 2326.35it/s]\n",
      "693441it [05:03, 2284.49it/s]\n",
      "77050it [00:34, 2202.34it/s]\n",
      "77050it [00:33, 2307.76it/s]\n"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "trainSet = FusionDataset(tr_in[:train_split],tokenizer,\\\n",
    "                         glyph2ix,pinyin2ix,pos2ix,tr_out[:train_split],\\\n",
    "                         tr_pos_in[:train_split],tr_pos_out[:train_split],\\\n",
    "                         device=device) # use device if you want to load it gpu"
=======
    "split_idx = int(len(tr_in) * 0.9)\n",
    "trainSet = FusionDataset(tr_in[:split_idx],tokenizer,glyph2ix,pinyin2ix,pos2ix,tr_out[:split_idx],tr_pos_in[:split_idx],tr_pos_out[:split_idx])\n",
    "valSet = FusionDataset(tr_in[split_idx:],tokenizer,glyph2ix,pinyin2ix,pos2ix,tr_out[split_idx:],tr_pos_in[split_idx:],tr_pos_out[split_idx:])"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "blessed-checklist",
=======
   "execution_count": 35,
   "id": "regulation-torture",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "ordered-significance",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77050it [00:33, 2273.61it/s]\n",
      "77050it [00:34, 2241.22it/s]\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "valSet = FusionDataset(tr_in[train_split:],tokenizer,\\\n",
    "                       glyph2ix,pinyin2ix,pos2ix,tr_out[train_split:],\\\n",
    "                       tr_pos_in[train_split:],tr_pos_out[train_split:],\\\n",
    "                       device=device) # use device if you want to load it gpu"
=======
    "batch_size = 64\n",
    "trainLoader = DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "validLoader = DataLoader(valSet,batch_size=batch_size,shuffle=False)"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "id": "sensitive-victory",
=======
   "execution_count": 12,
   "id": "statutory-indicator",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "execution_count": 14,
     "id": "protective-sixth",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "from model.fusion_transformer import Fusion_Anchi_Trans_Decoder, Fusion_Anchi_Transformer, Anchi_Decoder,Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "id": "approved-suffering",
=======
   "execution_count": 13,
   "id": "swedish-classroom",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "rental-settlement",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "config = { # for Fusion_Anchi_Trans_Decoder\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30,\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10,\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_layers':6,\n",
    "    'output_dim':21128 # fixed\n",
    "}\n",
    "config2 = { # Fusion_Anchi_Transformer\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30,\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10,\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_encoder_layers':6,\n",
    "    'num_decoder_layers':6,\n",
    "    'output_dim':21128, # fixed\n",
    "    'dim_feedforward': 3072,\n",
    "    'activation':'relu',\n",
    "    'trans_dropout':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "id": "available-orchestra",
=======
   "execution_count": 14,
   "id": "future-washer",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "execution_count": 16,
     "id": "handmade-ghana",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "model = Fusion_Anchi_Trans_Decoder(config)"
=======
    "model = Fusion_Anchi_Trans_Decoder(config).to(device)"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "instructional-gambling",
=======
   "execution_count": 15,
   "id": "understanding-musical",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "execution_count": 8,
     "id": "suspected-transition",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Fusion_Anchi_Transformer(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-season",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "execution_count": 16,
     "id": "fiscal-radius",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FusionEmbedding(\n",
       "  (position_embeddings): Embedding(50, 768)\n",
       "  (glyph_embeddings): GlyphEmbedding(\n",
       "    (embedding): Embedding(9110, 576)\n",
       "  )\n",
       "  (pinyin_embeddings): PinyinEmbedding(\n",
       "    (embedding): Embedding(1297, 30, padding_idx=0)\n",
       "  )\n",
       "  (pos_tag_embeddings): Embedding(30, 10, padding_idx=0)\n",
       "  (fc): Linear(in_features=1384, out_features=768, bias=True)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model3 = FusionEmbedding(config)\n",
    "# model3"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "characteristic-hybrid",
   "metadata": {
    "gradient": {
     "id": "corporate-trader",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "source": [
    "## Train Function"
=======
   "cell_type": "code",
   "execution_count": 62,
   "id": "93e4163a-8844-402a-9558-a6bff502008e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-6c4c148aa990>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAnchibert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-ee4265469c5a>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, Anchibert, data, num_epochs, save_model_name, optimizer, criterion, device, valid_loss_min)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAnchibert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-96e991eed6c2>\u001b[0m in \u001b[0;36mepoch_train\u001b[1;34m(net, Anchibert, dataLoader, optimizer, criterion, device, mode)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "save_model_name = 'decoder_md.pt'\n",
    "\n",
    "model = Fusion_Anchi_Trans_Decoder(config).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "train_net(model, Anchibert, [trainLoader, validLoader], epochs, save_model_name, optimizer, criterion, device = 'cpu')"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "id": "moving-celebration",
   "metadata": {
    "gradient": {
     "execution_count": 5,
     "id": "dedicated-starter",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff446d98350>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF_WRITER = False\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter('pytorch_results')\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "torch.manual_seed(1)"
=======
   "execution_count": 59,
   "id": "aee7cf8e-6239-48ad-9963-1093943db331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(net, Anchibert, dataLoader, optimizer, criterion, device = 'cuda0', mode = 'train'):\n",
    "    valid_loss = 0.0\n",
    "    for data in dataLoader:\n",
    "        data = [data_sub.to(device) for data_sub in data]\n",
    "        \n",
    "        Xsents_input_ids,Xsents_token_type_ids,\\\n",
    "        Xsents_attention_mask,Xsents_pinyin_ids,\\\n",
    "        Xsents_glyph_ids,Xsents_pos_ids,\\\n",
    "        Ysents_input_ids,Ysents_token_type_ids,\\\n",
    "        Ysents_attention_mask,Ysents_pinyin_ids,\\\n",
    "        Ysents_glyph_ids,Ysents_pos_ids = data\n",
    "\n",
    "        \n",
    "        Xword_embeddings = Anchibert(Xsents_input_ids,      \\\n",
    "                                     Xsents_token_type_ids, \\\n",
    "                                     Xsents_attention_mask  \\\n",
    "                                    )['last_hidden_state'].detach()\n",
    "\n",
    "\n",
    "        Yword_embeddings = Anchibert(Ysents_input_ids,      \\\n",
    "                                     Ysents_token_type_ids, \\\n",
    "                                     Ysents_attention_mask  \\\n",
    "                                    )['last_hidden_state'].detach()\n",
    "        \n",
    "        # outputs1 for Fusion_Anchi_Trans_Decoder\n",
    "        outputs1 = model(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "                        Xsents_token_type_ids,Xsents_pos_ids,\\\n",
    "                        Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "                        Ysents_token_type_ids,Ysents_pos_ids,\\\n",
    "                        Xsents_attention_mask.bool(),Ysents_attention_mask.bool())\n",
    "\n",
    "        # get the true model output label from decoder input id\n",
    "        trueY = torch.zeros(Ysents_input_ids.shape,dtype=torch.long,device=device)\n",
    "        trueY[:,:-1] = Ysents_input_ids[:,1:]\n",
    "        # find the index of first padding return 0 if no_padding \n",
    "        indices = torch.argmin(Ysents_attention_mask,dim=1).tolist()\n",
    "\n",
    "        for i, index in enumerate(indices):\n",
    "            trueY[i,index-1] = 102\n",
    "        trueY = trueY.view(-1)\n",
    "\n",
    "        outputs1 = outputs1.view(-1,outputs1.shape[-1])    \n",
    "        loss = criterion(outputs1,trueY)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            valid_loss += loss.item()*data[0].size(0)\n",
    "            \n",
    "    valid_loss = valid_loss/len(dataLoader.dataset)\n",
    "    return valid_loss\n",
    "\n"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "id": "specified-banks",
   "metadata": {
    "gradient": {
     "execution_count": 32,
     "id": "sitting-consortium",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model,dataLoader,optimizer,loss_function,\n",
    "                bert, device,with_trans=True):\n",
    "    \"\"\"Train one epoch of the model\"\"\"\n",
    "    epoch_loss = 0    \n",
    "    model.train()\n",
    "    \n",
    "    for Xsents_input_ids,Xsents_token_type_ids,\\\n",
    "        Xsents_attention_mask,Xsents_pinyin_ids,\\\n",
    "        Xsents_glyph_ids,Xsents_pos_ids,\\\n",
    "        Ysents_input_ids,Ysents_token_type_ids,\\\n",
    "        Ysents_attention_mask,Ysents_pinyin_ids,\\\n",
    "        Ysents_glyph_ids,Ysents_pos_ids in dataLoader:\n",
    "#         Ysents_glyph_ids,Ysents_pos_ids in tqdm(dataLoader):\n",
    "\n",
    "#         Xsents_input_ids = Xsents_input_ids.to(device)\n",
    "#         Xsents_token_type_ids = Xsents_token_type_ids.to(device)\n",
    "#         Xsents_attention_mask = Xsents_attention_mask.to(device)\n",
    "#         Xsents_pinyin_ids = Xsents_pinyin_ids.to(device)\n",
    "#         Xsents_glyph_ids = Xsents_glyph_ids.to(device)\n",
    "#         Xsents_pos_ids = Xsents_pos_ids.to(device)\n",
    "#         Ysents_input_ids = Ysents_input_ids.to(device)\n",
    "#         Ysents_token_type_ids = Ysents_token_type_ids.to(device)\n",
    "#         Ysents_attention_mask = Ysents_attention_mask.to(device)\n",
    "#         Ysents_pinyin_ids = Ysents_pinyin_ids.to(device)\n",
    "#         Ysents_glyph_ids = Ysents_glyph_ids.to(device)\n",
    "#         Ysents_pos_ids = Ysents_pos_ids.to(device)\n",
    "        \n",
    "        Xword_embeddings = bert(Xsents_input_ids,      \\\n",
    "                                 Xsents_token_type_ids, \\\n",
    "                                 Xsents_attention_mask  \\\n",
    "                                 )['last_hidden_state'].detach()\n",
    "\n",
    "\n",
    "        Yword_embeddings = bert(Ysents_input_ids,      \\\n",
    "                                Ysents_token_type_ids, \\\n",
    "                                Ysents_attention_mask  \\\n",
    "                               )['last_hidden_state'].detach()\n",
    "        \n",
    "        inputs = {'Xword_embeddings':Xword_embeddings, \\\n",
    "                  'Xsents_pinyin_ids':Xsents_pinyin_ids, \\\n",
    "                  'Xsents_glyph_ids':Xsents_glyph_ids,\\\n",
    "                  'Xsents_pos_ids':Xsents_pos_ids,\\\n",
    "                  'Yword_embeddings':Yword_embeddings,\\\n",
    "                  'Ysents_pinyin_ids':Ysents_pinyin_ids, \\\n",
    "                  'Ysents_glyph_ids':Ysents_glyph_ids,\\\n",
    "                  'Ysents_pos_ids':Ysents_pos_ids, \\\n",
    "                  'device':device}\n",
    "        \n",
    "        if with_trans:\n",
    "            inputs['Xpad_hidden_mask'] = (~ Xsents_attention_mask.bool()).detach()\n",
    "            inputs['Ypad_hidden_mask'] = (~ Ysents_attention_mask.bool()).detach()\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        outputs = model(**inputs) # [batch_size,max_length,output_dim]\n",
    "        outputs = outputs.view(-1,outputs.shape[-1])   #[batch_size*max_length,output_dim]\n",
    "                \n",
    "        # get the true model output label from decoder input id\n",
    "        trueY = torch.zeros(Ysents_input_ids.shape,dtype=torch.long,device=device)\n",
    "        trueY[:,:-1] = Ysents_input_ids[:,1:]\n",
    "        # find the index of first padding return 0 if no_padding \n",
    "        indices = torch.argmin(Ysents_attention_mask,dim=1).tolist()\n",
    "\n",
    "        for i, index in enumerate(indices):\n",
    "            trueY[i,index-1] = 102\n",
    "        trueY = trueY.view(-1)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_function(outputs,trueY)\n",
    "        \n",
    "        # with torch.autograd.detect_anomaly():\n",
    "        \n",
    "        # Get gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataLoader)"
=======
   "execution_count": 60,
   "id": "04ba5e17-702c-4930-b5e9-036b423adf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, Anchibert, data, num_epochs, save_model_name, optimizer, criterion, device = 'cuda0', valid_loss_min = np.Inf):\n",
    "    train_data = data[0]\n",
    "    valid_data = data[1]\n",
    "    \n",
    "    net = net.to(device)\n",
    "    Anchibert = Anchibert.to(device)\n",
    "        \n",
    "    for i in range(num_epochs):\n",
    "        net = net.train()\n",
    "        _ = epoch_train(net, Anchibert, train_data, optimizer, criterion, device)\n",
    "\n",
    "        net = net.eval()\n",
    "        valid_loss = epoch_train(net, Anchibert, train_data, optimizer, criterion, device, mode = 'valid')\n",
    "        \n",
    "        \n",
    "        print(f'epoch = {i}, loss = {valid_loss}')\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print(f'epoch = {i}')\n",
    "            print('Validation loss ({:.4f} --> {:.4f}).'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "\n",
    "            torch.save(net.state_dict(), save_model_name)\n",
    "            valid_loss_min = valid_loss\n"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "id": "racial-wyoming",
=======
   "execution_count": 24,
   "id": "continued-blowing",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   "metadata": {
    "gradient": {
     "execution_count": 26,
     "id": "prerequisite-elizabeth",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(model,dataLoader,loss_function,\n",
    "                   bert, device,with_trans=True):\n",
    "    \"\"\"Evaluate one epoch of the model\"\"\"\n",
    "    epoch_loss = 0    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "         for Xsents_input_ids,Xsents_token_type_ids,\\\n",
    "            Xsents_attention_mask,Xsents_pinyin_ids,\\\n",
    "            Xsents_glyph_ids,Xsents_pos_ids,\\\n",
    "            Ysents_input_ids,Ysents_token_type_ids,\\\n",
    "            Ysents_attention_mask,Ysents_pinyin_ids,\\\n",
    "            Ysents_glyph_ids,Ysents_pos_ids in dataLoader:\n",
    "#             Ysents_glyph_ids,Ysents_pos_ids in tqdm(dataLoader):\n",
    "\n",
    "#             Xsents_input_ids = Xsents_input_ids.to(device)\n",
    "#             Xsents_token_type_ids = Xsents_token_type_ids.to(device)\n",
    "#             Xsents_attention_mask = Xsents_attention_mask.to(device)\n",
    "#             Xsents_pinyin_ids = Xsents_pinyin_ids.to(device)\n",
    "#             Xsents_glyph_ids = Xsents_glyph_ids.to(device)\n",
    "#             Xsents_pos_ids = Xsents_pos_ids.to(device)\n",
    "#             Ysents_input_ids = Ysents_input_ids.to(device)\n",
    "#             Ysents_token_type_ids = Ysents_token_type_ids.to(device)\n",
    "#             Ysents_attention_mask = Ysents_attention_mask.to(device)\n",
    "#             Ysents_pinyin_ids = Ysents_pinyin_ids.to(device)\n",
    "#             Ysents_glyph_ids = Ysents_glyph_ids.to(device)\n",
    "#             Ysents_pos_ids = Ysents_pos_ids.to(device)\n",
    "\n",
    "            Xword_embeddings = bert(Xsents_input_ids,      \\\n",
    "                                     Xsents_token_type_ids, \\\n",
    "                                     Xsents_attention_mask  \\\n",
    "                                     )['last_hidden_state'].detach()\n",
    "\n",
    "\n",
    "            Yword_embeddings = bert(Ysents_input_ids,      \\\n",
    "                                    Ysents_token_type_ids, \\\n",
    "                                    Ysents_attention_mask  \\\n",
    "                                   )['last_hidden_state'].detach()\n",
    "\n",
    "            inputs = {'Xword_embeddings':Xword_embeddings, \\\n",
    "                      'Xsents_pinyin_ids':Xsents_pinyin_ids, \\\n",
    "                      'Xsents_glyph_ids':Xsents_glyph_ids,\\\n",
    "                      'Xsents_pos_ids':Xsents_pos_ids,\\\n",
    "                      'Yword_embeddings':Yword_embeddings,\\\n",
    "                      'Ysents_pinyin_ids':Ysents_pinyin_ids, \\\n",
    "                      'Ysents_glyph_ids':Ysents_glyph_ids,\\\n",
    "                      'Ysents_pos_ids':Ysents_pos_ids, \\\n",
    "                      'device':device}\n",
    "\n",
<<<<<<< HEAD
    "            if with_trans:\n",
    "                inputs['Xpad_hidden_mask'] = (~ Xsents_attention_mask.bool()).detach()\n",
    "                inputs['Ypad_hidden_mask'] = (~ Ysents_attention_mask.bool()).detach()\n",
    "\n",
    "\n",
    "            outputs = model(**inputs) # [batch_size,max_length,output_dim]\n",
    "            outputs = outputs.view(-1,outputs.shape[-1])   #[batch_size*max_length,output_dim]\n",
    "\n",
    "            # get the true model output label from decoder input id\n",
    "            trueY = torch.zeros(Ysents_input_ids.shape,dtype=torch.long,device=device)\n",
    "            trueY[:,:-1] = Ysents_input_ids[:,1:]\n",
    "            # find the index of first padding return 0 if no_padding \n",
    "            indices = torch.argmin(Ysents_attention_mask,dim=1).tolist()\n",
    "\n",
    "            for i, index in enumerate(indices):\n",
    "                trueY[i,index-1] = 102\n",
    "            trueY = trueY.view(-1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_function(outputs,trueY)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "desirable-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainSet,validSet,batch_size,lr, epoch,bert,name= None,\n",
    "          with_trans= True,if_writer=False,optimizer_name= 'Adam',\n",
    "          scheduleFactor=0.5,schedule_Patience=5,\n",
    "          min_lr=1e-06, verbose=True, patience= 10):\n",
    "    \"\"\"\n",
    "    Training a given neural network model\n",
    "    Return a Best model object in state_dict() fashion\n",
    "    \n",
    "    @Para:\n",
    "    model: pytorch training model\n",
    "    trainSet: Tensor Dataset\n",
    "    validSet: Tensor Dataset\n",
    "    batch_size: batch_size\n",
    "    lr: initial learning rate\n",
    "    epoch: num of epoch\n",
    "    bert: transformers.models.bert.modeling_bert.BertModel\n",
    "    name: Model name\n",
    "    with_trans: If True, a transformer padding mask will be generated as forward input. \n",
    "    \n",
    "    if_writer: True for using tensorboard to trail\n",
    "        the train loss and the valid loss at each epoch\n",
    "    \n",
    "    scheduleFactor: reduce factor for learning rate\n",
    "    schedule_Patience:(int): Number of epochs with no improvement after\n",
    "        which learning rate will be reduced. For example, if\n",
    "        `patience = 2`, then we will ignore the first 2 epochs\n",
    "        with no improvement, and will only decrease the LR after the\n",
    "        3rd epoch if the loss still hasn't improved then.\n",
    "        Default: 10.\n",
=======
    "    Yword_embeddings = Anchibert(Ysents_input_ids,      \\\n",
    "                                 Ysents_token_type_ids, \\\n",
    "                                 Ysents_attention_mask  \\\n",
    "                                )['last_hidden_state'].detach()\n",
    "    # outputs1 for Fusion_Anchi_Trans_Decoder\n",
    "    outputs1 = model(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "                    Xsents_token_type_ids,Xsents_pos_ids,\\\n",
    "                    Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "                    Ysents_token_type_ids,Ysents_pos_ids,\\\n",
    "                    Xsents_attention_mask.bool(),Ysents_attention_mask.bool())\n",
    "    \n",
    "    # outputs2 Fusion_Anchi_Transformer(config2)\n",
    "#     outputs2= model2(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "#                     Xsents_token_type_ids,Xsents_pos_ids,\\\n",
    "#                     Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "#                     Ysents_token_type_ids,Ysents_pos_ids,\\\n",
    "#                     Xsents_attention_mask.bool(),Ysents_attention_mask.bool())\n",
    "    \n",
    "    # FusionEmbedding\n",
    "#     outputembeddingsX = model3(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "#                          Xsents_token_type_ids,Xsents_pos_ids)\n",
    "#     outputembeddingsY = model3(Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "#                              Ysents_token_type_ids,Ysents_pos_ids)\n",
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
    "    \n",
    "    min_lr: min_lr\n",
    "    verbose: True for print train loss and valid loss at each epoch\n",
    "    patience:  Number of epochs with no improvement after\n",
    "        which training will be stopped. For example, if\n",
    "        `patience = 2`, then we will ignore the first 2 epochs\n",
    "        with no improvement, and will only stops after the\n",
    "        3rd epoch if the valid loss still hasn't improved then.\n",
    "        Default: 5.\n",
    "    \"\"\"\n",
    "     # Instantiate Train Loader and Valid Loader\n",
    "    trainLoader = DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "    validLoader = DataLoader(validSet,batch_size=batch_size,shuffle=False)\n",
    "    if if_writer:\n",
    "        writer = SummaryWriter('pytorch_results')\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    bert.to(device)\n",
    "\n",
    "    # Instantiate loss class\n",
    "    criterion = nn.NLLLoss(ignore_index=0)\n",
    "    \n",
    "    # Iniantiate optimizer class\n",
    "    lr = lr\n",
    "    \n",
    "    # Iniantiate optimizer class\n",
    "    if optimizer_name:\n",
    "        optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(),lr = lr, momentum=.9, nesterov=True)\n",
    "\n",
    "     # Reduce on Loss Plateau Learning rate scheduler\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optimizer,factor=scheduleFactor,patience=schedule_Patience, min_lr=min_lr,verbose=verbose)\n",
    "    \n",
    "    # Instantiate Best model and Best Valid Loss\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
<<<<<<< HEAD
    "    valid_patience_counter = 0\n",
    "    \n",
    "    n_epoch = epoch\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train model (average)\n",
    "        train_loss = train_epoch(model,trainLoader,optimizer,\n",
    "                                 criterion,bert,device,with_trans)\n",
    "        \n",
    "        # Decay Learning Rate\n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        ##############\n",
    "        # validation #\n",
    "        ##############\n",
    "        valid_loss = evaluate_epoch(model,validLoader,criterion,\n",
    "                                               bert,device,with_trans)\n",
    "        mins,secs = timeparser(time.time()-start_time)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        if if_writer:\n",
    "            writer.add_scalar(f\"{name} Train Loss\", train_loss, epoch)\n",
    "            writer.add_scalar(f\"{name} Valid Loss\", valid_loss,epoch)\n",
    "            writer.add_scalars(f\"{name} Loss/Epoch\", {'train': train_loss,\n",
    "                                                    'valid': valid_loss},\n",
    "                                epoch+1)\n",
    "        \n",
    "        if verbose:\n",
    "            # Print Learning Rate and Loss for ecach Loss\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {mins}m {secs}s')\n",
    "            print(f'\\tTraining Loss: {train_loss:.5f} \\tValidation Loss: {valid_loss:.5f}')\n",
    "        \n",
    "        # Compare the Valid Loss with Best Valid Loss\n",
    "        if valid_loss< best_valid_loss:\n",
    "            # reset counter\n",
    "            valid_patience_counter = 0\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "            best_valid_loss = valid_loss\n",
    "        else:\n",
    "            valid_patience_counter += 1\n",
    "            if valid_patience_counter == patience:\n",
    "                if if_writer:\n",
    "                    writer.flush()\n",
    "                    writer.close()\n",
    "                return best_model,train_losses,valid_losses\n",
    "    if if_writer:\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "    return best_model, train_losses,valid_losses\n"
=======
    "    outputs1 = outputs1.view(-1,outputs1.shape[-1])    \n",
    "    loss = criterion(outputs1,trueY)\n",
    "    loss.backward()\n",
    "    break"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "mineral-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "name = 'fusion_decoder_64_1_100_'\n",
    "best_model,train_losses,valid_losses = train(model,trainSet,valSet,\n",
    "                                          batch_size=64,lr=0.1,\n",
    "                                          epoch=100,bert=Anchibert,\n",
    "                                          name= name,\n",
    "                                          with_trans=True,if_writer=False,\n",
    "                                          optimizer_name='Adam',scheduleFactor=0.5,\n",
    "                                          schedule_Patience=5,min_lr=1e-06,\n",
    "                                          verbose=True,patience=10\n",
    "                                         )"
=======
   "execution_count": 41,
   "id": "3e1e0fe7-a86f-4f55-aed2-8df7947332a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1792])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueY.size()"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "negative-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,f'{name}.pt')\n",
    "with open(f'{name}_losses.pt','w') as f:\n",
    "    pickle.dump((train_losses,valid_losses),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model)"
=======
   "id": "unknown-texas",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "valued-extent",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs.shape, outputs2.shape, outputembeddingsX.shape,outputembeddingsY.shape"
>>>>>>> 628b74b27622ff0479c70665ee7498c51670a059
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-bristol",
   "metadata": {},
   "source": [
    "### Way to generate new decoder input from raw sentence \n",
    "\n",
    "记得把model output 中 不存在 glyph dict的词以及'[SEP]' 和'[PAD]'给转换成 '_'。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-sacramento",
   "metadata": {
    "gradient": {
     "execution_count": 21,
     "id": "cardiovascular-redhead",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['晨', '露', '润', '花', '花', '更', '红'], ['万', '方', '乐', '奏', '有', '于', '阗']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = tr_out[:2]\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-estonia",
   "metadata": {
    "gradient": {
     "execution_count": 24,
     "id": "basic-station",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n",
      "DEBUG:jieba._compat:Paddle enabled successfully......\n",
      "2it [00:00, 83.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([ 101, 3247, 7463, 3883, 5709, 5709, 3291, 5273], dtype=torch.int32),\n",
       "  tensor([ 101,  674, 3175,  727, 1941, 3300,  754,  100], dtype=torch.int32)],\n",
       " [tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)],\n",
       " [tensor([1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)],\n",
       " [tensor([  0, 717,  59, 873, 579, 579, 217, 334], dtype=torch.int32),\n",
       "  tensor([   0,  187,  476,  501,  807, 1178,  263, 1002], dtype=torch.int32)],\n",
       " [tensor([   0, 5656, 1568, 3172, 3915, 3915, 3367, 8111], dtype=torch.int32),\n",
       "  tensor([   0, 1729, 3171, 4526, 2058, 8413, 3025, 6866], dtype=torch.int32)],\n",
       " [tensor([ 0,  4,  4,  4,  4,  4, 16, 12], dtype=torch.int32),\n",
       "  tensor([ 0, 26, 26, 26, 26,  9, 27, 27], dtype=torch.int32)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FusionDataset.prepare_sequence(sents=sents, tokenizer=tokenizer,\n",
    "                               glyph2ix=glyph2ix,pinyin2ix=pinyin2ix,\n",
    "                               pos2ix=pos2ix,encode=False,skip_error=False,\n",
    "                               device=device) # use device if you want to load it gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-timeline",
   "metadata": {},
   "source": [
    "#### Section for testing train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twelve-rapid",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "opening-great",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2223.45it/s]\n",
      "1000it [00:00, 2323.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tempSet = FusionDataset(tr_in[:1000],tokenizer,glyph2ix,pinyin2ix,pos2ix,tr_out[:1000],tr_pos_in[:1000],tr_pos_out[:1000])\n",
    "tempLoader = DataLoader(tempSet,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-tuner",
   "metadata": {
    "gradient": {
     "execution_count": 11,
     "id": "rapid-consumer",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.1)\n",
    "criterion = nn.NLLLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Anchibert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strong-johnston",
   "metadata": {
    "gradient": {
     "execution_count": 20,
     "id": "adaptive-guard",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "model = Anchi_Transformer(config2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lyric-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Anchi_Decoder(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comparable-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "model = Fusion_Anchi_Transformer(config2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "voluntary-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "model = Fusion_Anchi_Trans_Decoder(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "facial-public",
   "metadata": {
    "gradient": {
     "execution_count": 33,
     "id": "mental-smith",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.62it/s]\n"
     ]
    }
   ],
   "source": [
    "res = train_epoch(model,tempLoader,optimizer,criterion,Anchibert,device,with_trans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hawaiian-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.56it/s]\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_epoch(model,tempLoader,criterion,Anchibert,device,with_trans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-magnet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
