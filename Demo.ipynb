{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "express-invite",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "extended-trigger",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 21.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.53.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.1.2 tokenizers-0.10.3 transformers-4.12.5\n",
      "Collecting pypinyin\n",
      "  Downloading pypinyin-0.44.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pypinyin\n",
      "Successfully installed pypinyin-0.44.0\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 23.7 MB/s eta 0:00:01     |████████████████████████████████| 19.1 MB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=55efb52c6a4b2bbef62efbe8a22c702b22196ed5785a2351f79907185c38168c\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/38/d8/dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Collecting paddlepaddle\n",
      "  Downloading paddlepaddle-2.2.0-cp38-cp38-manylinux1_x86_64.whl (108.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 108.2 MB 121 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle) (2.24.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from paddlepaddle) (1.15.0)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 28.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from paddlepaddle) (4.4.2)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /opt/conda/lib/python3.8/site-packages (from paddlepaddle) (1.19.2)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle) (3.14.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2020.12.5)\n",
      "Installing collected packages: Pillow, astor, paddlepaddle\n",
      "Successfully installed Pillow-8.4.0 astor-0.8.1 paddlepaddle-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pypinyin\n",
    "!pip install jieba\n",
    "!pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stunning-insertion",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "wrong-airport",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AnchiBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re,time,json\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from pypinyin import pinyin, Style\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import (BertTokenizer,BertConfig,BertModel)\n",
    "\n",
    "from model.Embedding import FusionEmbedding,GlyphEmbedding,PinyinEmbedding\n",
    "from model.fusionDataset import FusionDataset\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import paddle\n",
    "\n",
    "config = BertConfig.from_pretrained('AnchiBERT')\n",
    "tokenizer = BertTokenizer.from_pretrained('AnchiBERT')\n",
    "Anchibert = BertModel.from_pretrained('AnchiBERT',config=config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-vacuum",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "massive-ministry",
     "kernelId": ""
    }
   },
   "source": [
    "### Example for glyph + pinyin embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-homeless",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fuzzy-corner",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0421, -0.0327,  0.0096,  ...,  0.0711,  0.0417, -0.0224],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2590,  0.2719,  0.1614,  0.0099,  0.1555, -0.2728,  0.2700, -0.1006,\n",
       "         -0.0885,  0.0607,  0.2121,  0.1352,  0.1809, -0.0842,  0.2739, -0.2115,\n",
       "         -0.2756, -0.1202,  0.0751, -0.2282, -0.2437, -0.2295,  0.2278, -0.2172,\n",
       "          0.0318, -0.2727,  0.0463, -0.2532, -0.1979,  0.1673]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glyph = GlyphEmbedding('data/glyph_weight.npy')\n",
    "pinyinV = PinyinEmbedding(30,'data/pinyin_map.json')\n",
    "# Example\n",
    "display(glyph(torch.tensor([0,1,2])))\n",
    "display(pinyinV(torch.tensor([0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-usage",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "equal-store",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  100, 6789,  689, 2591,  223,    0,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "_ = tokenizer('[UNK]辛业怠π[PAD]',return_tensors='pt')\n",
    "display(_)\n",
    "Anchibert(**_).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-spelling",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "gorgeous-perception",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '辛', '业', '怠', 'π', '[PAD]', '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(_['input_ids'][0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-microwave",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "front-blogger",
     "kernelId": ""
    }
   },
   "source": [
    "### Load Necessary preproceeded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "egyptian-residence",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "funky-penguin",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "with open('data/char_map.json','r') as f:\n",
    "    glyph2ix = defaultdict(lambda : 1)\n",
    "    glyph2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    glyph2ix.update(json.load(f))\n",
    "\n",
    "with open('data/pinyin_map.json','r') as f:\n",
    "    pinyin2ix = defaultdict(lambda : 1)\n",
    "    pinyin2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    pinyin2ix.update(json.load(f))\n",
    "    \n",
    "with open('data/pos_tags.json','r') as f:\n",
    "    pos2ix = defaultdict(lambda : 0)\n",
    "    pos2ix.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excellent-elite",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "alike-appointment",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# train 上联\n",
    "with open(\"couplet/train/in.txt\",encoding='utf8') as f:\n",
    "    tr_in =  [row.strip().split() for row in f.readlines()]\n",
    "# train 下联  \n",
    "with open(\"couplet/train/out.txt\",encoding='utf8') as f:\n",
    "    tr_out = [row.strip().split() for row in f.readlines()]\n",
    "with open('data/train_in_pos.pt','rb') as f:\n",
    "    tr_pos_in = pickle.load(f)\n",
    "with open('data/train_out_pos.pt','rb') as f:\n",
    "    tr_pos_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improving-fundamental",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "temporal-replacement",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [00:00, 2153.05it/s]\n",
      "110it [00:00, 2263.32it/s]\n"
     ]
    }
   ],
   "source": [
    "trainSet = FusionDataset(tr_in[:110],tokenizer,glyph2ix,pinyin2ix,pos2ix,tr_out[:110],tr_pos_in[:110],tr_pos_out[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-torture",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "returning-spiritual",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainSet,batch_size=64,shuffle=True)\n",
    "#     validLoader = DataLoader(validSet,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statutory-indicator",
   "metadata": {
    "gradient": {
     "execution_count": 12,
     "id": "standard-budapest",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "from model.fusion_transformer import Fusion_Anchi_Trans_Decoder, Fusion_Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-classroom",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "green-college",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "config = { # for Fusion_Anchi_Trans_Decoder\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30,\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10,\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_layers':6,\n",
    "    'output_dim':21128 # fixed\n",
    "}\n",
    "config2 = { # Fusion_Anchi_Transformer\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30,\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10,\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_encoder_layers':6,\n",
    "    'num_decoder_layers':6,\n",
    "    'output_dim':21128, # fixed\n",
    "    'dim_feedforward': 3072,\n",
    "    'activation':'relu',\n",
    "    'trans_dropout':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "future-washer",
   "metadata": {
    "gradient": {
     "execution_count": 14,
     "id": "disturbed-analysis",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# model = Fusion_Anchi_Trans_Decoder(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "understanding-musical",
   "metadata": {
    "gradient": {
     "execution_count": 15,
     "id": "trained-demand",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "model2 = Fusion_Anchi_Transformer(config2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-integration",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "execution_count": 16,
     "id": "suspected-consumption",
     "kernelId": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FusionEmbedding(\n",
       "  (position_embeddings): Embedding(50, 768)\n",
       "  (glyph_embeddings): GlyphEmbedding(\n",
       "    (embedding): Embedding(9110, 576)\n",
       "  )\n",
       "  (pinyin_embeddings): PinyinEmbedding(\n",
       "    (embedding): Embedding(1297, 30, padding_idx=0)\n",
       "  )\n",
       "  (pos_tag_embeddings): Embedding(30, 10, padding_idx=0)\n",
       "  (fc): Linear(in_features=1384, out_features=768, bias=True)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model3 = FusionEmbedding(config)\n",
    "# model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aggressive-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "several-operations",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model2.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continued-blowing",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "established-margin",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "Anchibert.to(device)\n",
    "for Xsents_input_ids,Xsents_token_type_ids,\\\n",
    "    Xsents_attention_mask,Xsents_pinyin_ids,\\\n",
    "    Xsents_glyph_ids,Xsents_pos_ids,\\\n",
    "    Ysents_input_ids,Ysents_token_type_ids,\\\n",
    "    Ysents_attention_mask,Ysents_pinyin_ids,\\\n",
    "    Ysents_glyph_ids,Ysents_pos_ids in trainLoader:\n",
    "    \n",
    "    Xsents_input_ids = Xsents_input_ids.to(device)\n",
    "    Xsents_token_type_ids = Xsents_token_type_ids.to(device)\n",
    "    Xsents_attention_mask = Xsents_attention_mask.to(device)\n",
    "    Xsents_pinyin_ids = Xsents_pinyin_ids.to(device)\n",
    "    Xsents_glyph_ids = Xsents_glyph_ids.to(device)\n",
    "    Xsents_pos_ids = Xsents_pos_ids.to(device)\n",
    "    Ysents_input_ids = Ysents_input_ids.to(device)\n",
    "    Ysents_token_type_ids = Ysents_token_type_ids.to(device)\n",
    "    Ysents_attention_mask = Ysents_attention_mask.to(device)\n",
    "    Ysents_pinyin_ids = Ysents_pinyin_ids.to(device)\n",
    "    Ysents_glyph_ids = Ysents_glyph_ids.to(device)\n",
    "    Ysents_pos_ids = Ysents_pos_ids.to(device)\n",
    "    \n",
    "    Xword_embeddings = Anchibert(Xsents_input_ids,      \\\n",
    "                                 Xsents_token_type_ids, \\\n",
    "                                 Xsents_attention_mask  \\\n",
    "                                )['last_hidden_state'].detach()\n",
    "\n",
    "\n",
    "    Yword_embeddings = Anchibert(Ysents_input_ids,      \\\n",
    "                                 Ysents_token_type_ids, \\\n",
    "                                 Ysents_attention_mask  \\\n",
    "                                )['last_hidden_state'].detach()\n",
    "    # outputs1 for Fusion_Anchi_Trans_Decoder\n",
    "#     outputs1 = model(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "#                     Xsents_token_type_ids,Xsents_pos_ids,\\\n",
    "#                     Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "#                     Ysents_token_type_ids,Ysents_pos_ids,\\\n",
    "#                     Xsents_attention_mask.bool(),Ysents_attention_mask.bool())\n",
    "    \n",
    "    # outputs2 Fusion_Anchi_Transformer(config2)\n",
    "    outputs2= model2(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "                    Xsents_token_type_ids,Xsents_pos_ids,\\\n",
    "                    Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "                    Ysents_token_type_ids,Ysents_pos_ids,\\\n",
    "                    Xsents_attention_mask.bool(),Ysents_attention_mask.bool())\n",
    "    \n",
    "    # FusionEmbedding\n",
    "#     outputembeddingsX = model3(Xword_embeddings,Xsents_pinyin_ids, \\\n",
    "#                          Xsents_token_type_ids,Xsents_pos_ids)\n",
    "#     outputembeddingsY = model3(Yword_embeddings,Ysents_pinyin_ids, \\\n",
    "#                              Ysents_token_type_ids,Ysents_pos_ids)\n",
    "    \n",
    "    \n",
    "    # get the true model output label from decoder input id\n",
    "    trueY = torch.zeros(Ysents_input_ids.shape,dtype=torch.long,device=device)\n",
    "    trueY[:,:-1] = Ysents_input_ids[:,1:]\n",
    "    # find the index of first padding return 0 if no_padding \n",
    "    indices = torch.argmin(Ysents_attention_mask,dim=1).tolist()\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        trueY[i,index-1] = 102\n",
    "    trueY = trueY.view(-1)\n",
    "    \n",
    "    outputs2 = outputs2.view(-1,outputs2.shape[-1])    \n",
    "    loss = criterion(outputs2,trueY)\n",
    "    loss.backward()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-texas",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "valued-extent",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 64, 21128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, outputs2.shape, outputembeddingsX.shape,outputembeddingsY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-purple",
   "metadata": {},
   "source": [
    "### Way to generate new decoder input from raw sentence \n",
    "\n",
    "记得把model output 中 不存在 glyph dict的词以及'[SEP]' 和'[PAD]'给转换成 '_'。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "featured-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['晨', '露', '润', '花', '花', '更', '红'], ['万', '方', '乐', '奏', '有', '于', '阗']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = tr_out[:2]\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cognitive-edward",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n",
      "DEBUG:jieba._compat:Paddle enabled successfully......\n",
      "2it [00:00, 83.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([ 101, 3247, 7463, 3883, 5709, 5709, 3291, 5273], dtype=torch.int32),\n",
       "  tensor([ 101,  674, 3175,  727, 1941, 3300,  754,  100], dtype=torch.int32)],\n",
       " [tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)],\n",
       " [tensor([1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)],\n",
       " [tensor([  0, 717,  59, 873, 579, 579, 217, 334], dtype=torch.int32),\n",
       "  tensor([   0,  187,  476,  501,  807, 1178,  263, 1002], dtype=torch.int32)],\n",
       " [tensor([   0, 5656, 1568, 3172, 3915, 3915, 3367, 8111], dtype=torch.int32),\n",
       "  tensor([   0, 1729, 3171, 4526, 2058, 8413, 3025, 6866], dtype=torch.int32)],\n",
       " [tensor([ 0,  4,  4,  4,  4,  4, 16, 12], dtype=torch.int32),\n",
       "  tensor([ 0, 26, 26, 26, 26,  9, 27, 27], dtype=torch.int32)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FusionDataset.prepare_sequence(sents=sents, tokenizer=tokenizer,\n",
    "                               glyph2ix=glyph2ix,pinyin2ix=pinyin2ix,\n",
    "                               pos2ix=pos2ix,encode=False,skip_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-breakdown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
