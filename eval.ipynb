{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3d3f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "c:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate import bleu\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "from nltk.lm.models import Laplace\n",
    "from nltk.lm import Vocabulary\n",
    "\n",
    "from utils.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3f884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"couplet/test/out.txt\", encoding = 'utf8') as f:\n",
    "    gold = [line.strip().split() for line in f.readlines()]\n",
    "# with open(\"couplet/output.txt\", encoding = 'utf8') as f:\n",
    "#     y_pred = [line.strip().split() for line in f.readlines()]\n",
    "with open(\"couplet/train/in.txt\", encoding = 'utf8') as f:\n",
    "    tr_in =  [line.strip().split() for line in f.readlines()]\n",
    "with open(\"couplet/train/out.txt\", encoding = 'utf8') as f:\n",
    "    tr_out =  [line.strip().split() for line in f.readlines()]\n",
    "with open(\"couplet/test/in.txt\", encoding = 'utf8') as f:\n",
    "    te_in = [line.strip().split() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c367c-829e-4cd9-b937-24b21e3f17ca",
   "metadata": {},
   "source": [
    "## Evaluation Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f142c7a4-c565-4eef-8f01-85fae74750b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.774001598220131, [146.49264761345754, 284.2561369557696])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.evaluation import *\n",
    "\n",
    "a = ['夜幕',\n",
    " '莺声溅']\n",
    "\n",
    "evaluate_pred(a, a, 'perplexity_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40963752",
   "metadata": {},
   "source": [
    "## Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feb640ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bleu score on the test set is:  0.03177547785577113\n"
     ]
    }
   ],
   "source": [
    "smoothfct = SmoothingFunction().method2\n",
    "bleu_score = 0\n",
    "for i in range(len(gold)):\n",
    "    bleu_score += bleu([te_in[i]], gold[i], smoothing_function = smoothfct)\n",
    "avg_bleu = bleu_score / len(gold)\n",
    "print(\"Average bleu score on the test set is: \", avg_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23071b",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffde110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram\n",
    "n = 2\n",
    "train_sentences = tr_in + tr_out\n",
    "words = [word for sentence in train_sentences for word in sentence]\n",
    "words.extend([\"<s>\", \"<e>\"])\n",
    "vocab = Vocabulary(words)\n",
    "train_data = [nltk.bigrams(pad_both_ends(t, n = n)) for t in train_sentences]\n",
    "\n",
    "\n",
    "lm = Laplace(n)\n",
    "lm.fit(train_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d112abb5-6f61-4d46-8bf5-19f17ee13658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('perplexity_model.pt', 'wb')\n",
    "pickle.dump(lm, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c86e5ee-9642-4343-982c-b4a106f38c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('perplexity_model.pt', 'rb')\n",
    "lm = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "083c97f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP(和谐南供，安全送电保畅通，争做领头羊):375.9619036414558\n",
      "PP(夜幕已沉梦更闲):605.4699869560575\n",
      "PP(莺声溅落柳枝头):150.26441075846543\n"
     ]
    }
   ],
   "source": [
    "test_data = [nltk.bigrams(pad_both_ends(t, n = n)) for t in y_pred]\n",
    "\n",
    "for i, test in enumerate(test_data[:3]):\n",
    "    print(\"PP({0}):{1}\".format(''.join(y_pred[i]), lm.perplexity(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bb92482-5639-48e2-8b6d-1bb51a432b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e9dfcda798f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mperplexity\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \"\"\"\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_ngrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36mentropy\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m    167\u001b[0m         return -1 * _mean(\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_ngrams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         )\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\py36\\lib\\site-packages\\nltk\\lm\\api.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;34m\"\"\"Return average (aka mean) for sequence of items.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "lm.perplexity(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram\n",
    "n = 3\n",
    "train_sentences = tr_in + tr_out\n",
    "words = [word for sentence in train_sentences for word in sentence]\n",
    "words.extend([\"<s>\", \"<e>\"])\n",
    "vocab = Vocabulary(words)\n",
    "train_data = [nltk.bigrams(pad_both_ends(t, n = n)) for t in train_sentences]\n",
    "\n",
    "\n",
    "lm = Laplace(n)\n",
    "lm.fit(train_data, vocab)\n",
    "\n",
    "test_data = [nltk.bigrams(pad_both_ends(t, n = n)) for t in y_pred]\n",
    "\n",
    "for i, test in enumerate(test_data):\n",
    "    print(\"PP({0}):{1}\".format(''.join(y_pred[i]), lm.perplexity(test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
