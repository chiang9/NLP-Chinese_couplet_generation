{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-barbados",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "boolean-diving",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install pypinyin\n",
    "!pip install jieba\n",
    "!pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-earth",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "metropolitan-times",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AnchiBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re,time,json\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from pypinyin import pinyin, Style\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import (BertTokenizer,BertConfig,BertModel)\n",
    "\n",
    "from model.Embedding import *\n",
    "from model.fusionDataset import FusionDataset\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import paddle\n",
    "\n",
    "config = BertConfig.from_pretrained('AnchiBERT')\n",
    "tokenizer = BertTokenizer.from_pretrained('AnchiBERT')\n",
    "Anchibert = BertModel.from_pretrained('AnchiBERT',config=config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "three-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from model.Embedding import FusionEmbedding,BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-footage",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "stable-checkout",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "source": [
    "### Load Necessary preproceeded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-sampling",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "funky-measurement",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/char_map.json','r') as f:\n",
    "    glyph2ix = defaultdict(lambda : 1)\n",
    "    glyph2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    glyph2ix.update(json.load(f))\n",
    "\n",
    "with open('data/pinyin_map.json','r') as f:\n",
    "    pinyin2ix = defaultdict(lambda : 1)\n",
    "    pinyin2ix.update({'[CLS]':0,'[SEP]':0,'[PAD]':0})\n",
    "    pinyin2ix.update(json.load(f))\n",
    "    \n",
    "with open('data/pos_tags.json','r') as f:\n",
    "    pos2ix = defaultdict(lambda : 0)\n",
    "    pos2ix.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sorted-biology",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "whole-israeli",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "# train 上联\n",
    "with open(\"couplet/train/in.txt\",encoding='utf8') as f:\n",
    "    tr_in =  [row.strip().split() for row in f.readlines()]\n",
    "# train 下联  \n",
    "with open(\"couplet/train/out.txt\",encoding='utf8') as f:\n",
    "    tr_out = [row.strip().split() for row in f.readlines()]\n",
    "with open('data/train_in_pos.pt','rb') as f:\n",
    "    tr_pos_in = pickle.load(f)\n",
    "with open('data/train_out_pos.pt','rb') as f:\n",
    "    tr_pos_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floral-infrastructure",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "designing-stage",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(tr_in))\n",
    "total_len = len(tr_in)\n",
    "half = total_len//1000\n",
    "display(half)\n",
    "train_split = int(0.80 * half)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-cylinder",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "played-lancaster",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "616it [00:00, 2360.08it/s]\n",
      "616it [00:00, 2297.67it/s]\n"
     ]
    }
   ],
   "source": [
    "trainSet = FusionDataset(tr_in[:train_split],tokenizer,\\\n",
    "                         glyph2ix,pinyin2ix,pos2ix,tr_out[:train_split],\\\n",
    "                         tr_pos_in[:train_split],tr_pos_out[:train_split],\\\n",
    "                         device=device) # use device if you want to load it gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resident-camcorder",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "ordered-significance",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:00, 2402.53it/s]\n",
      "154it [00:00, 2431.42it/s]\n"
     ]
    }
   ],
   "source": [
    "valSet = FusionDataset(tr_in[train_split:half],tokenizer,\\\n",
    "                       glyph2ix,pinyin2ix,pos2ix,tr_out[train_split:half],\\\n",
    "                       tr_pos_in[train_split:half],tr_pos_out[train_split:half],\\\n",
    "                       device=device) # use device if you want to load it gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enclosed-mexico",
   "metadata": {
    "gradient": {
     "execution_count": 14,
     "id": "protective-sixth",
     "kernelId": "583276d5-8a0a-4f47-9ffe-672fe9cb301f"
    }
   },
   "outputs": [],
   "source": [
    "from model.fusion_transformer import Fusion_Anchi_Trans_Decoder, Fusion_Anchi_Transformer, Anchi_Decoder,Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handled-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trans_trainer import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-boston",
   "metadata": {},
   "source": [
    "## Fusion_Anchi_Trans_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recreational-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 24s\n",
      "\tTraining Loss: 8.58321 \tValidation Loss: 7.02125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:25<00:25, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTraining Loss: 6.70914 \tValidation Loss: 6.72863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:49<00:00, 24.66s/it]\n"
     ]
    }
   ],
   "source": [
    "config = { # for Fusion_Anchi_Trans_Decoder\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30, # trainable\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10, # trainable\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_layers':6, # trainable\n",
    "    'output_dim':21128,# fixed\n",
    "    'device':device,\n",
    "}\n",
    "# batch_size = [32,64,128]\n",
    "# lr =[0.1,0.01,0.001]\n",
    "# name = 'anchi_tra_de_128_01_10_'\n",
    "name = 'test'\n",
    "train(Fusion_Anchi_Trans_Decoder(config),trainSet,valSet,batch_size=128,lr=0.01,\n",
    "      epoch=2,bert=Anchibert,name= name, with_trans=True,\n",
    "      optimizer_name='Adam',scheduleFactor=0.5,\n",
    "      schedule_Patience=5,min_lr=1e-06,verbose=True\n",
    "      ,patience=10,store='result/')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifth-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Fusion_Anchi_Transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joined-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainSet[0:2]\n",
    "bert = Anchibert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tested-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsents_input_ids,Xsents_token_type_ids,\\\n",
    "        Xsents_attention_mask,Xsents_pinyin_ids,\\\n",
    "        Xsents_glyph_ids,Xsents_pos_ids,\\\n",
    "        Ysents_input_ids,Ysents_token_type_ids,\\\n",
    "        Ysents_attention_mask,Ysents_pinyin_ids,\\\n",
    "        Ysents_glyph_ids,Ysents_pos_ids,trueY,y_mask_ids = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elementary-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xword_embeddings = bert(Xsents_input_ids,      \\\n",
    "                         Xsents_token_type_ids, \\\n",
    "                         Xsents_attention_mask  \\\n",
    "                         )['last_hidden_state'].detach()\n",
    "\n",
    "\n",
    "Yword_embeddings = bert(Ysents_input_ids,      \\\n",
    "                        Ysents_token_type_ids, \\\n",
    "                        Ysents_attention_mask  \\\n",
    "                       )['last_hidden_state'].detach()\n",
    "\n",
    "inputs = {'Xword_embeddings':Xword_embeddings, \\\n",
    "          'Xsents_pinyin_ids':Xsents_pinyin_ids, \\\n",
    "          'Xsents_glyph_ids':Xsents_glyph_ids,\\\n",
    "          'Xsents_pos_ids':Xsents_pos_ids,\\\n",
    "          'Yword_embeddings':Yword_embeddings,\\\n",
    "          'Ysents_pinyin_ids':Ysents_pinyin_ids, \\\n",
    "          'Ysents_glyph_ids':Ysents_glyph_ids,\\\n",
    "          'Ysents_pos_ids':Ysents_pos_ids, \\\n",
    "          'device':device}\n",
    "inputs['Xpad_hidden_mask'] = (~ Xsents_attention_mask.bool()).detach()\n",
    "inputs['Ypad_hidden_mask'] = (~ Ysents_attention_mask.bool()).detach()\n",
    "inputs['tgt_mask']= y_mask_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrapped-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 29])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mask_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "warming-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 2, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = model.encode(**inputs)\n",
    "model.decode(memory,**inputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-romantic",
   "metadata": {},
   "source": [
    "## Anchi_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hispanic-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 22s\n",
      "\tTraining Loss: 8.37719 \tValidation Loss: 6.93155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.40s/it]\n"
     ]
    }
   ],
   "source": [
    "config = { # for Trans_Decoder\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'layer_norm_eps':1e-12,\n",
    "    'hidden_dropout':0.1,\n",
    "    'nhead':12,\n",
    "    'num_layers':6, # trainable\n",
    "    'output_dim':21128, # fixed\n",
    "    'device':device\n",
    "}\n",
    "name = 'test'\n",
    "train(Anchi_Decoder(config),trainSet,valSet,batch_size=128,lr=0.01,\n",
    "      epoch=1,bert=Anchibert,name= name, with_trans=True,\n",
    "      optimizer_name='Adam',scheduleFactor=0.5,\n",
    "      schedule_Patience=5,min_lr=1e-06,verbose=True\n",
    "      ,patience=10,store='result/')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-beach",
   "metadata": {},
   "source": [
    "## Fusion_Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "looking-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "\tTraining Loss: 10.20252 \tValidation Loss: 10.53441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n"
     ]
    }
   ],
   "source": [
    "config = { # Fusion_Anchi_Transformer\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'font_weight_path':'data/glyph_weight.npy',\n",
    "    'pinyin_embed_dim':30, # trainable\n",
    "    'pinyin_path':'data/pinyin_map.json',\n",
    "    'tag_size':30,\n",
    "    'tag_emb_dim':10, # trainable \n",
    "    'layer_norm_eps':1e-12, \n",
    "    'hidden_dropout':0.1, \n",
    "    'nhead':12,\n",
    "    'num_encoder_layers':5, # trainable\n",
    "    'num_decoder_layers':6, # trainable\n",
    "    'output_dim':21128, # fixed\n",
    "    'dim_feedforward': 3072,\n",
    "    'activation':'relu',\n",
    "    'trans_dropout':0.1,\n",
    "    'device':device\n",
    "}\n",
    "# name = 'A_Tran_De_128_01_60_Adam_tag10_e5_d6'\n",
    "name ='test'\n",
    "train(Fusion_Anchi_Transformer(config),trainSet,valSet,batch_size=128,lr=0.01,\n",
    "      epoch=1,bert=Anchibert,name= name, with_trans=True,\n",
    "      optimizer_name='Adam',scheduleFactor=0.5,\n",
    "      schedule_Patience=5,min_lr=1e-06,verbose=True\n",
    "      ,patience=5,store='result/')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-arbitration",
   "metadata": {},
   "source": [
    "## Anchi_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "heavy-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "\tTraining Loss: 10.89027 \tValidation Loss: 13.99074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:16,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 2s\n",
      "\tTraining Loss: 10.05464 \tValidation Loss: 10.73588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTraining Loss: 8.31517 \tValidation Loss: 9.38932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:12<00:08,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTraining Loss: 7.54540 \tValidation Loss: 9.03403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:16<00:04,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\tTraining Loss: 7.17033 \tValidation Loss: 8.48137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "config = { # Anchi_Transformer\n",
    "    'max_position_embeddings':50,\n",
    "    'hidden_size':768,\n",
    "    'layer_norm_eps':1e-12, \n",
    "    'hidden_dropout':0.1, \n",
    "    'nhead':12,\n",
    "    'num_encoder_layers':6, # trainable\n",
    "    'num_decoder_layers':6, # trainable\n",
    "    'output_dim':21128, # fixed\n",
    "    'dim_feedforward': 3072,\n",
    "    'activation':'relu',\n",
    "    'trans_dropout':0.1,\n",
    "    'device':device\n",
    "}\n",
    "name = 'test'\n",
    "train(Anchi_Transformer(config),trainSet,valSet,batch_size=128,lr=0.01,\n",
    "      epoch=5,bert=Anchibert,name= name, with_trans=True,\n",
    "      optimizer_name='Adam',scheduleFactor=0.5,\n",
    "      schedule_Patience=5,min_lr=1e-06,verbose=True\n",
    "      ,patience=10,store='result/')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-teens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
