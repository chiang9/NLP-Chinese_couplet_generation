%
% File acl2015.tex
%
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2015}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Chinese Couplet Generation Status Report}

\author{
  Kuan-Yu Chiang\\
  \texttt{kuanyu@usc.edu}
  \\\And
  Qian Yin\\
  \texttt{qianyin@usc.edu}
  \\\And
  Joe Chen\\
  \texttt{zchen462@usc.edu}
  \\\AND
  Shihao Lin\\
  \texttt{shihaol@usc.edu}
  \\\And
  Qizhen Jin\\
  \texttt{qizhenji@usc.edu}
}
 
\date{2021/10/19}

\begin{document}
\maketitle

\section{Tasks Performed}


\subsection{Data Exploration and Preprocessing}

To date, We had explored the dataset we proposed in the proposal. The Chinese Couplets Dataset contains 770,491 training data with various length and proper syntax. Due to the unique syntax of Chinese Couplet, additional attention is required in validating our dataset. We had successfully implemented the Embedding weighted by utilizing the pretrained weight from Google BERT-base-Chinese. 

\subsection{Model}

The implementation of model had not been started yet, however, we had designed our model architecture. We plan to use the Bilingual Evaluation Understudy (BLEU) and Rouge Score as our model Evaluation metrics.

\section{Risk and Challenges}

We are currently behind our schedule of the original plan. 

\subsection{Data}

Due to the complexity of the Chinese language, some issues might arise. 

\begin{itemize}
  \item It is likely that the BERT Embedding might not contains some Chinese characters in our training set or test set.
  \item Due to different syntax, additional attention to positional encoding might be needed in generating our dataset.
\end{itemize}

\subsection{Model Implementation}

To date, we have not implemented our model yet, we will encounter issues in implementing our model, and might need additional cloud help in model training.

\section{Current Plans to Mitigate Risks}

\subsection{Team Collaboration}

We are currently behind our schedule of original plan. To expedite the project implementation, we plan to set deadlines for milestones of the project, and assign tasks to each of the group members.  

\subsection{Data Preprocessing}

To avoid losing information of unseen word in the BERT embedding, we can lower the restriction of the \textit{Unknown} tag, and set the embedding to be trainable. 

Data Preprocessing is essential in improving our neural network. We plan to use rule-based algorithm in generating the syntax information, and use it as a parameter in our model. Also, we can employ the Chinese part-of-speech (POS) tag as parameter to enhance the cohesion between words.

\subsection{Model Implementation}

We plan to use BiLSTM+CRF with positional encoding and add syntax parameters we generated and part-of-speech (POS) tag to our dataset preprocessing.

In order to resolve the potential hardware limitation for model training, we can use the AWS platform to utilize the education credit from the course.

\section{Significant Challenges that Changes Our Direction}

Our model architecture did not vary significantly from our proposal, we add some more features, such as the syntax information and the part-of-speech (POS) tag to enhance our model. 


\end{document}