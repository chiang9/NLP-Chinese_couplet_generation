{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817dcb9-150c-4739-8906-c4ea6a7c0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130ff9c-052e-46c6-8ea2-a4778a3a0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用的paddlenlp的word embeddings，具体看 https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/embeddings.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0106c12-fd69-4535-a2e4-6052eedd7b77",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3784046c-ead1-4607-a8bb-5e6d5f049d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2914da-2182-40da-9fb7-70d7c010a489",
   "metadata": {},
   "source": [
    "### 1.1 Load and Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093e5639-731c-4fab-bbe0-f5e15642b37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-28 22:41:20,517] [    INFO] - Loading token embedding...\n",
      "[2021-11-28 22:41:31,392] [    INFO] - Finish loading embedding vector.\n",
      "[2021-11-28 22:41:31,394] [    INFO] - Token Embedding info:             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Shape :[635965, 300]\n"
     ]
    }
   ],
   "source": [
    "tr_in = open(\"couplet/train/in.txt\",encoding='utf8').read()\n",
    "tr_out = open(\"couplet/train/out.txt\",encoding='utf8').read()\n",
    "te_in = open(\"couplet/test/in.txt\",encoding='utf8').read()\n",
    "te_out = open(\"couplet/test/out.txt\",encoding='utf8').read()\n",
    "\n",
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "token_embedding = TokenEmbedding(embedding_name=\"w2v.baidu_encyclopedia.target.word-word.dim300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99889536-2da6-40d5-8a2a-0cacf597f7db",
   "metadata": {},
   "source": [
    "### 1.2 Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4646dab9-b2c2-4cbd-997b-4210e78dd01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(tr_in + tr_out + te_in + te_out))\n",
    "vocab.insert(0,'<EOS>')\n",
    "vocab.insert(0,'<BOS>')\n",
    "vocab.insert(0,'<PAD>')\n",
    "\n",
    "embeddings = dict()\n",
    "embeddings[2] = np.random.rand(300,).astype('float32') *2 - 1 # range(-1:1)\n",
    "embeddings[1] = np.random.rand(300,).astype('float32') *2 - 1 # range(-1:1)\n",
    "embeddings[0] = np.zeros(300,)\n",
    "\n",
    "for i,w in enumerate(vocab,start = 3):\n",
    "    embeddings[i] = token_embedding.search(w).reshape(300,)\n",
    "    \n",
    "word2idx = {w:i for i,w in enumerate(vocab)}\n",
    "idx2word = {i:w for i,w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10eb1bc-ce17-4a3b-b107-e7be8aa755b5",
   "metadata": {},
   "source": [
    "### 1.3 Word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63becea8-5c83-479c-ac34-32e180105df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x, y, word2id):\n",
    "    in_sentences = [[word2id[w] for w in sent.split()] for sent in x]\n",
    "    out_sentences = [[word2id[w] for w in sent.split()] for sent in y]\n",
    "    \n",
    "    # 根据句子的长度排序\n",
    "    #sorted_len = sorted([ (i,len(x)) for i,x in enumerate(tr_in.split('\\n')[:-3000])], key=lambda x: x[1])\n",
    "    \n",
    "    #sorted_index = [x[0] for x in sorted_len]\n",
    "    #in_sentences = [in_sentences[i] for i in sorted_index]\n",
    "    #out_sentences = [out_sentences[i] for i in sorted_index]\n",
    "    \n",
    "    return in_sentences, out_sentences\n",
    "\n",
    "train_x, train_y = convert(tr_in.split('\\n')[:-3000], tr_out.split('\\n')[:-3000], word2idx)\n",
    "dev_x, dev_y = convert(tr_in.split('\\n')[-3000:], tr_out.split('\\n')[-3000:], word2idx)\n",
    "test_x, test_y = convert(te_in.split('\\n')[:-1], te_out.split('\\n')[:-1], word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "421b7e40-55a5-421b-9ec9-ced329a5d90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4163, 3696, 3597, 3805, 3805, 3928, 1823]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818d3e1-f50b-4b70-a183-1519e74993ce",
   "metadata": {},
   "source": [
    "### 1.4 Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb822937-b866-479a-8c23-7555ea577b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个函数的作用是我们输入训练集的样本个数， batch_size大小， 就会返回多批 连续的batch_size个索引， 每一个索引代表一个样本\n",
    "# 也就是可以根据这个索引去拿到一个个的batch\n",
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx+minibatch_size, n)))\n",
    "    return minibatches      # 这个会返回多批连着的bath_size个索引  \n",
    "#get_minibatches(len(train_en), 32)\n",
    "\n",
    "# 这个函数是在做数据预处理， 由于每个句子都不是一样长， 所以通过这个函数就可以把句子进行补齐， 不够长的在句子后面添加0\n",
    "def prepare_data(seqs):\n",
    "    lengths = [len(seq) for seq in seqs]    # 得到每个句子的长度\n",
    "    n_samples = len(seqs)       # 得到一共有多少个句子\n",
    "    max_len = np.max(lengths)              # 找出最大的句子长度\n",
    "    \n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')    # 按照最大句子长度生成全0矩阵\n",
    "    x_lengths = np.array(lengths).astype('int32')\n",
    "    for idx, seq in enumerate(seqs):        # 把有句子的位置填充进去\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths      # x_mask\n",
    "\n",
    "def gen_examples(en_sentences, cn_sentences, batch_size):\n",
    "    minibatches = get_minibatches(len(en_sentences), batch_size)   # 得到batch个索引\n",
    "    all_ex = []\n",
    "    for minibatch in minibatches:   # 每批数据的索引\n",
    "        mb_en_sentences = [en_sentences[t] for t in minibatch]   # 取数据\n",
    "        mb_cn_sentences = [cn_sentences[t] for t in minibatch]  # 取数据\n",
    "        mb_x, mb_x_len = prepare_data(mb_en_sentences) # 填充成一样的长度， 但是要记录一下句子的真实长度， 这个在后面输入网络的时候得用\n",
    "        mb_y, mb_y_len = prepare_data(mb_cn_sentences)\n",
    "        all_ex.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return all_ex\n",
    "\n",
    "batch_size = 64\n",
    "train_data = gen_examples(train_x, train_y, batch_size)   # 产生训练集\n",
    "random.shuffle(train_data)\n",
    "dev_data = gen_examples(dev_x, dev_y, batch_size)   # 产生验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d65a153-fcf6-4f43-aa11-6ccb168ba4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8461,  937, 8009, ...,    0,    0,    0],\n",
       "       [3253, 7172, 2463, ..., 2821, 6084, 4154],\n",
       "       [6971,  453, 1519, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [5279,  209, 3087, ...,    0,    0,    0],\n",
       "       [5393, 3700,  753, ...,    0,    0,    0],\n",
       "       [1631, 5295, 3815, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239c03f-b606-4067-b3d6-2801bac1f843",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7071aa-827d-4752-ba1d-4506a5def66f",
   "metadata": {},
   "source": [
    "### 2.1 Encoder(GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc0556a1-723e-4b70-a2e8-a5ec63894d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size*2, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))   # [batch_size, seq_len, embed_size]\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)  # [batch_size, seq_len, 2*enc_hidden_size]\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous()   # [batch_size, seq_len, 2*enc_hidden_size]\n",
    "        hid = hid[:, original_idx.long()].contiguous()   # [2, batch_size, enc_hidden_size]\n",
    "        \n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1)   # 双向的GRU， 这里是最后一个状态， 联结起来  [batch_size, 2*enc_hidden_size]\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0)  # [1, batch_size, dec_hidden_size]\n",
    "        \n",
    "        return out, hid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b220048-687b-47d3-94c1-efa2d1d8590d",
   "metadata": {},
   "source": [
    "### 2.2 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc1f6684-02c3-42a0-922f-3e4ba87372af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.linear_in = nn.Linear(enc_hidden_size*2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size*2+dec_hidden_size, dec_hidden_size)\n",
    "    \n",
    "    def forward(self, output, encoder_output, mask):\n",
    "        # output: [batch_size, seq_len_y-1, dec_hidden_size]  这个output 是decoder的每个时间步输出的隐藏状态\n",
    "        # encoder_output: [batch_size, seq_len_x, 2*enc_hidden_size]\n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = encoder_output.size(1)\n",
    "        \n",
    "        context_in = self.linear_in(encoder_output.view(batch_size*input_len, -1))  # [batch_size*seq_len_x,dec_hidden_size]\n",
    "        context_in = context_in.view(batch_size, input_len, -1)  # [batch_size, seq_len_x, dec_hidden_size]\n",
    "        context_in = context_in.transpose(1, 2)   # [batch_size, dec_hidden_size, seq_len_x]\n",
    "        \n",
    "        attn = torch.bmm(output, context_in)  # [batch_size, seq_len_y-1, seq_len_x]\n",
    "        # 这个东西就是求得当前时间步的输出output和所有输入相似性关系的一个得分score , 下面就是通过softmax把这个得分转成权重\n",
    "        attn = F.softmax(attn, dim=2)    # 此时第二维度的数字全都变成了0-1之间的数， 越大表示当前的输出output与哪个相关程度越大\n",
    "        \n",
    "        context = torch.bmm(attn, encoder_output)   # [batch_size, seq_len_y-1, 2*enc_hidden_size]\n",
    "        \n",
    "        output = torch.cat((context, output), dim=2)  # [batch_size, seq_len_y-1, 2*enc_hidden_size+dec_hidden_size]\n",
    "        \n",
    "        output = output.view(batch_size*output_len, -1)   # [batch_size*seq_len_y-1, 2*enc_hidden_size+dec_hidden_size]\n",
    "        output = torch.tanh(self.linear_out(output))     # [batch_size*seq_len_y-1, dec_hidden_size]\n",
    "        output = output.view(batch_size, output_len, -1)  # [batch_size, seq_len_y-1, dec_hidden_size]\n",
    "        \n",
    "        return output, attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6917b-7b35-4bbb-a7bc-dbb1304c9523",
   "metadata": {},
   "source": [
    "### 2.3 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7c02c73-0247-4605-b2cf-9db82418ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def create_mask(self, x_len, y_len):\n",
    "        # a mask of shape x_len*y_len\n",
    "        x_mask = torch.arange(x_len.max(), device=x_len.device)[None, :] < x_len[:, None]\n",
    "        y_mask = torch.arange(y_len.max(), device=x_len.device)[None, :] < y_len[:, None]\n",
    "        \n",
    "        x_mask = x_mask.float()\n",
    "        y_mask = y_mask.float()\n",
    "        mask = (1 - x_mask[:, :, None] * y_mask[:, None, :]).byte()\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, encoder_out, encoder_out_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()]   # 句子从长到短排序\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "        \n",
    "        y_sorted = self.dropout(self.embed(y_sorted))     # [batch_size, output_length, embed_size]\n",
    "        \n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_idx.long()].contiguous()   # [batch_size, seq_len_y-1, dec_hidden_size]\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "        \n",
    "        mask = self.create_mask(y_lengths, encoder_out_lengths)\n",
    "        \n",
    "        output, attn = self.attention(output_seq, encoder_out, mask)\n",
    "        output = F.log_softmax(self.out(output), -1)\n",
    "        \n",
    "        return output, hid, attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c4daa-583f-4066-b886-5585deb7ccb2",
   "metadata": {},
   "source": [
    "### 2.4 Wrapped Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8b50c53-cbdf-4b14-8d1d-72508a063c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(encoder_out, x_lengths, y, y_lengths, hid)\n",
    "        \n",
    "        return output, attn\n",
    "    \n",
    "    def translate(self, x, x_lengths, y, max_length=100):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(encoder_out, x_lengths, y, torch.ones(batch_size).long().to(y.device), hid)\n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            attns.append(attn)\n",
    "        \n",
    "        return torch.cat(preds, 1), torch.cat(attns, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43935b-2a2e-49b3-9a56-b63dd7c95720",
   "metadata": {},
   "source": [
    "### 2.5 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16276c9b-ae8a-4b00-b9f6-2f4ccf507694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked cross entropy loss\n",
    "class LanguageModelCriterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LanguageModelCriterion, self).__init__()\n",
    "    \n",
    "    def forward(self, input, target, mask):\n",
    "        # input: [batch_size, seq_len, vocab_size]    每个单词的可能性\n",
    "        input = input.contiguous().view(-1, input.size(2))   # [batch_size*seq_len-1, vocab_size]\n",
    "        target = target.contiguous().view(-1, 1)    #  [batch_size*seq_len-1, 1]\n",
    "        \n",
    "        mask = mask.contiguous().view(-1, 1)   # [batch_size*seq_len-1, 1]\n",
    "        output = -input.gather(1, target) * mask # 在每个vocab_size维度取正确单词的索引， 但是里面有很多是填充进去的， 所以mask去掉这些填充的\n",
    "        # 这个其实在写一个NLloss ， 也就是sortmax的取负号\n",
    "        output = torch.sum(output) / torch.sum(mask)\n",
    "        \n",
    "        return output  # [batch_size*seq_len-1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e72c1ed-622e-4902-854c-6512de61fc86",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a73ce-1550-478e-ab16-3d5820848141",
   "metadata": {},
   "source": [
    "### Config Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b41998b5-ee75-4be1-9a9f-4007a9fd22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dropout = 0.2\n",
    "hidden_size = 100\n",
    "encoder = Encoder(vocab_size=len(word2id), enc_hidden_size=hidden_size, dec_hidden_size=hidden_size, embed_size = 300, dropout=dropout)\n",
    "decoder = Decoder(vocab_size=len(word2id), enc_hidden_size=hidden_size, dec_hidden_size=hidden_size, embed_size = 300, dropout=dropout)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "loss_fn = LanguageModelCriterion().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2240802e-7787-45d0-97f8-ef6e1f6c4fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3020, 1469, 2508, ...,    0,    0,    0],\n",
       "        [3413, 1469, 4390, ...,    0,    0,    0],\n",
       "        [7793, 1469, 1029, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [5923, 1469, 7262, ...,    0,    0,    0],\n",
       "        [3062, 1469, 5898, ...,    0,    0,    0],\n",
       "        [1494, 1469, 6855, ...,    0,    0,    0]]),\n",
       " array([26, 14, 24, 28, 24, 34,  4, 24, 14, 14, 14, 32, 14, 34, 12, 20, 38,\n",
       "        10, 24, 14, 56, 24, 14, 18, 10, 26, 48, 24, 18, 14,  4, 18, 22, 14,\n",
       "        14, 14, 14, 14, 14, 36, 10, 12, 14, 24, 24, 14, 36, 10, 18,  8, 14,\n",
       "        12, 18, 26, 14, 14, 14, 14, 22, 14,  4, 46, 24, 18]),\n",
       " array([[3708, 1469, 3100, ...,    0,    0,    0],\n",
       "        [ 937, 1469, 8173, ...,    0,    0,    0],\n",
       "        [8642, 1469, 5316, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [5697, 1469, 2211, ...,    0,    0,    0],\n",
       "        [8172, 1469, 5495, ...,    0,    0,    0],\n",
       "        [3708, 1469, 5740, ...,    0,    0,    0]]),\n",
       " array([26, 14, 24, 28, 24, 34,  4, 24, 14, 14, 14, 32, 14, 34, 12, 20, 38,\n",
       "        10, 24, 14, 56, 24, 14, 18, 10, 26, 48, 24, 18, 14,  4, 18, 22, 14,\n",
       "        14, 14, 14, 14, 14, 36, 10, 12, 14, 24, 24, 14, 36, 10, 18,  8, 14,\n",
       "        12, 18, 26, 14, 14, 14, 14, 22, 14,  4, 46, 24, 18]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82b9d5-8003-4532-a375-8a7a5f8753ec",
   "metadata": {},
   "source": [
    "#### Train and evluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80d939b2-358e-4cb7-8879-fd2284754791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iteration 0 loss 2.2863216400146484\n",
      "Epoch 0 iteration 100 loss 2.1728837490081787\n",
      "Epoch 0 iteration 200 loss 2.1048381328582764\n",
      "Epoch 0 iteration 300 loss 2.2445578575134277\n",
      "Epoch 0 iteration 400 loss 2.1681671142578125\n",
      "Epoch 0 iteration 500 loss 2.302433490753174\n",
      "Epoch 0 iteration 600 loss 2.2872703075408936\n",
      "Epoch 0 iteration 700 loss 2.2662642002105713\n",
      "Epoch 0 iteration 800 loss 2.198660135269165\n",
      "Epoch 0 iteration 900 loss 2.1695706844329834\n",
      "Epoch 0 iteration 1000 loss 2.2012994289398193\n",
      "Epoch 0 iteration 1100 loss 2.187025785446167\n",
      "Epoch 0 iteration 1200 loss 2.2352516651153564\n",
      "Epoch 0 iteration 1300 loss 2.2365846633911133\n",
      "Epoch 0 iteration 1400 loss 2.2648298740386963\n",
      "Epoch 0 iteration 1500 loss 2.2279813289642334\n",
      "Epoch 0 iteration 1600 loss 2.256891965866089\n",
      "Epoch 0 iteration 1700 loss 2.3395471572875977\n",
      "Epoch 0 iteration 1800 loss 2.2788023948669434\n",
      "Epoch 0 iteration 1900 loss 2.2199950218200684\n",
      "Epoch 0 iteration 2000 loss 2.1266772747039795\n",
      "Epoch 0 iteration 2100 loss 2.1311628818511963\n",
      "Epoch 0 iteration 2200 loss 2.2709991931915283\n",
      "Epoch 0 iteration 2300 loss 2.1779751777648926\n",
      "Epoch 0 iteration 2400 loss 2.2781500816345215\n",
      "Epoch 0 iteration 2500 loss 2.0483717918395996\n",
      "Epoch 0 iteration 2600 loss 2.3191072940826416\n",
      "Epoch 0 iteration 2700 loss 2.238434314727783\n",
      "Epoch 0 iteration 2800 loss 2.284547805786133\n",
      "Epoch 0 iteration 2900 loss 2.1262338161468506\n",
      "Epoch 0 iteration 3000 loss 2.1549954414367676\n",
      "Epoch 0 iteration 3100 loss 2.2173962593078613\n",
      "Epoch 0 iteration 3200 loss 2.250253915786743\n",
      "Epoch 0 iteration 3300 loss 2.1340575218200684\n",
      "Epoch 0 iteration 3400 loss 2.3305578231811523\n",
      "Epoch 0 iteration 3500 loss 2.206803321838379\n",
      "Epoch 0 iteration 3600 loss 2.1674771308898926\n",
      "Epoch 0 iteration 3700 loss 2.1162166595458984\n",
      "Epoch 0 iteration 3800 loss 2.1760966777801514\n",
      "Epoch 0 iteration 3900 loss 2.280362606048584\n",
      "Epoch 0 iteration 4000 loss 2.1276354789733887\n",
      "Epoch 0 iteration 4100 loss 2.229710102081299\n",
      "Epoch 0 iteration 4200 loss 2.146838903427124\n",
      "Epoch 0 iteration 4300 loss 2.114931106567383\n",
      "Epoch 0 iteration 4400 loss 2.230691909790039\n",
      "Epoch 0 iteration 4500 loss 2.148817777633667\n",
      "Epoch 0 iteration 4600 loss 2.231199026107788\n",
      "Epoch 0 iteration 4700 loss 2.220529317855835\n",
      "Epoch 0 iteration 4800 loss 2.0449461936950684\n",
      "Epoch 0 iteration 4900 loss 2.2219934463500977\n",
      "Epoch 0 iteration 5000 loss 2.236492872238159\n",
      "Epoch 0 iteration 5100 loss 2.304717540740967\n",
      "Epoch 0 iteration 5200 loss 2.2644550800323486\n",
      "Epoch 0 iteration 5300 loss 2.0593950748443604\n",
      "Epoch 0 iteration 5400 loss 2.128755807876587\n",
      "Epoch 0 iteration 5500 loss 2.28857684135437\n",
      "Epoch 0 iteration 5600 loss 2.130751371383667\n",
      "Epoch 0 iteration 5700 loss 2.167863607406616\n",
      "Epoch 0 iteration 5800 loss 2.265038251876831\n",
      "Epoch 0 iteration 5900 loss 2.1224377155303955\n",
      "Epoch 0 iteration 6000 loss 2.0985848903656006\n",
      "Epoch 0 iteration 6100 loss 2.245422840118408\n",
      "Epoch 0 iteration 6200 loss 2.1628079414367676\n",
      "Epoch 0 iteration 6300 loss 2.165229558944702\n",
      "Epoch 0 iteration 6400 loss 2.3369758129119873\n",
      "Epoch 0 iteration 6500 loss 2.2181026935577393\n",
      "Epoch 0 iteration 6600 loss 2.0253396034240723\n",
      "Epoch 0 iteration 6700 loss 2.2723870277404785\n",
      "Epoch 0 iteration 6800 loss 2.1045477390289307\n",
      "Epoch 0 iteration 6900 loss 2.2371160984039307\n",
      "Epoch 0 iteration 7000 loss 2.161410331726074\n",
      "Epoch 0 iteration 7100 loss 2.1350326538085938\n",
      "Epoch 0 iteration 7200 loss 2.2448997497558594\n",
      "Epoch 0 iteration 7300 loss 2.2177562713623047\n",
      "Epoch 0 iteration 7400 loss 2.17972993850708\n",
      "Epoch 0 iteration 7500 loss 2.1597182750701904\n",
      "Epoch 0 iteration 7600 loss 2.1656150817871094\n",
      "Epoch 0 iteration 7700 loss 2.187479019165039\n",
      "Epoch 0 iteration 7800 loss 2.177075147628784\n",
      "Epoch 0 iteration 7900 loss 2.131406307220459\n",
      "Epoch 0 iteration 8000 loss 2.170506477355957\n",
      "Epoch 0 iteration 8100 loss 2.1337499618530273\n",
      "Epoch 0 iteration 8200 loss 2.1950714588165283\n",
      "Epoch 0 iteration 8300 loss 2.161871910095215\n",
      "Epoch 0 iteration 8400 loss 2.105384349822998\n",
      "Epoch 0 iteration 8500 loss 2.2127487659454346\n",
      "Epoch 0 iteration 8600 loss 2.2440106868743896\n",
      "Epoch 0 iteration 8700 loss 2.277979612350464\n",
      "Epoch 0 iteration 8800 loss 2.148580551147461\n",
      "Epoch 0 iteration 8900 loss 2.262697696685791\n",
      "Epoch 0 iteration 9000 loss 2.2663824558258057\n",
      "Epoch 0 iteration 9100 loss 2.1962239742279053\n",
      "Epoch 0 iteration 9200 loss 2.179349660873413\n",
      "Epoch 0 iteration 9300 loss 2.1901047229766846\n",
      "Epoch 0 iteration 9400 loss 2.17484188079834\n",
      "Epoch 0 iteration 9500 loss 2.258375883102417\n",
      "Epoch 0 iteration 9600 loss 2.1221914291381836\n",
      "Epoch 0 iteration 9700 loss 2.063730239868164\n",
      "Epoch 0 iteration 9800 loss 2.155179262161255\n",
      "Epoch 0 iteration 9900 loss 2.179323673248291\n",
      "Epoch 0 iteration 10000 loss 2.192782163619995\n",
      "Epoch 0 iteration 10100 loss 2.1104679107666016\n",
      "Epoch 0 iteration 10200 loss 2.076323986053467\n",
      "Epoch 0 iteration 10300 loss 2.3229541778564453\n",
      "Epoch 0 iteration 10400 loss 2.240358591079712\n",
      "Epoch 0 iteration 10500 loss 2.165616989135742\n",
      "Epoch 0 iteration 10600 loss 2.0562431812286377\n",
      "Epoch 0 iteration 10700 loss 2.1199352741241455\n",
      "Epoch 0 iteration 10800 loss 2.1184377670288086\n",
      "Epoch 0 iteration 10900 loss 2.200568437576294\n",
      "Epoch 0 iteration 11000 loss 2.178858518600464\n",
      "Epoch 0 iteration 11100 loss 2.171112060546875\n",
      "Epoch 0 iteration 11200 loss 2.170046329498291\n",
      "Epoch 0 iteration 11300 loss 2.111168384552002\n",
      "Epoch 0 iteration 11400 loss 2.170196771621704\n",
      "Epoch 0 iteration 11500 loss 2.105783700942993\n",
      "Epoch 0 iteration 11600 loss 2.176818609237671\n",
      "Epoch 0 iteration 11700 loss 2.102588176727295\n",
      "Epoch 0 iteration 11800 loss 1.9831345081329346\n",
      "Epoch 0 iteration 11900 loss 2.105952262878418\n",
      "Epoch 0 Training loss 2.177058737657086\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_6184/732621167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_6184/732621167.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data, num_epochs)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_num_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_6184/732621167.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mmb_y_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmb_y_len\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m1\u001b[0m   \u001b[1;31m# 这句话是为了以防出错\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mmb_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_x_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_y_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmb_out_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_y_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmb_y_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_6184/3825132505.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, x_lengths, y, y_lengths)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WINDOW~1\\AppData\\Local\\Temp/ipykernel_6184/4216657070.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, lengths)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# [batch_size, seq_len, embed_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mpacked_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mpacked_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_embedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [batch_size, seq_len, 2*enc_hidden_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "# 定义训练和验证函数\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    total_num_words = total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()    # 这个是一个batch的英文句子 大小是[batch_size, seq_len]\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()    # 每个句子的长度\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()  # 解码器那边的输入， 输入一个单词去预测另外一个单词\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()   # 解码器那边的输出  [batch_size, seq_len-1]\n",
    "            mb_y_len = torch.from_numpy(mb_y_len-1).to(device).long()  # 这个减去1， 因为没有了最后一个  [batch_size, seq_len-1]\n",
    "            mb_y_len[mb_y_len<=0] =  1   # 这句话是为了以防出错\n",
    "            \n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "            \n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]  \n",
    "            # [batch_size, mb_y_len.max()], 上面是bool类型， 下面是float类型， 只计算每个句子的有效部分， 填充的那部分去掉\n",
    "            mb_out_mask = mb_out_mask.float()  # [batch_size, seq_len-1]  因为mb_y_len.max()就是seq_len-1\n",
    "            \n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "            \n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "    print('Evaluation loss', total_loss / total_num_words)\n",
    "\n",
    "def train(model, data, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_num_words = total_loss = 0.\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in  enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len-1).to(device).long()\n",
    "            mb_y_len[mb_y_len<=0] = 1\n",
    "            \n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "            \n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "            \n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "            \n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "            \n",
    "            # 更新\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)     # 这里防止梯度爆炸， 这是和以往不太一样的地方\n",
    "            optimizer.step()\n",
    "            \n",
    "            if it % 100 == 0:\n",
    "                print('Epoch', epoch, 'iteration', it, 'loss', loss.item())\n",
    "\n",
    "        print('Epoch', epoch, 'Training loss', total_loss / total_num_words)\n",
    "        if epoch % 5 == 0:\n",
    "            evaluate(model, dev_data)\n",
    "        \n",
    "# 训练\n",
    "train(model, train_data, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dac5c48d-46eb-45b4-bed8-a318d127b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3020, 1469, 2508, 1469, 8798, 1469, 4261, 1469, 4261, 1469, 2340,\n",
       "       1469, 6683, 1469, 1101, 1469, 3225, 1469, 3458, 1469, 5898, 1469,\n",
       "       6747, 1469, 8078, 1469,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d4621-32d8-43a6-8dec-f9aaf0dd7220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
